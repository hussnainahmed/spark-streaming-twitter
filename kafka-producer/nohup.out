
/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
  InsecurePlatformWarning
/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
  InsecurePlatformWarning
Traceback (most recent call last):
  File "user_tweet_collector.py", line 45, in <module>
    tweet_data = twitterStream.filter(follow=['64622053','127483019','65635927','122453931','735314581','213539531'])
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 428, in filter
    self._start(async)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 346, in _start
    self._run()
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 255, in _run
    self._read_loop(resp)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 298, in _read_loop
    line = buf.read_line().strip()
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 171, in read_line
    self._buffer += self._stream.read(self._chunk_size).decode("ascii")
  File "/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/response.py", line 267, in read
    raise ReadTimeoutError(self._pool, None, 'Read timed out.')
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='stream.twitter.com', port=443): Read timed out.
/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
  InsecurePlatformWarning
Traceback (most recent call last):
  File "user_tweet_collector.py", line 45, in <module>
    tweet_data = twitterStream.filter(follow=['64622053','127483019','65635927','122453931','735314581','213539531'])
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 428, in filter
    self._start(async)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 346, in _start
    self._run()
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 255, in _run
    self._read_loop(resp)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 298, in _read_loop
    line = buf.read_line().strip()
AttributeError: 'NoneType' object has no attribute 'strip'
/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
  InsecurePlatformWarning
Traceback (most recent call last):
  File "user_tweet_collector.py", line 45, in <module>
    tweet_data = twitterStream.filter(follow=['64622053','127483019','65635927','122453931','735314581','213539531'])
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 428, in filter
    self._start(async)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 346, in _start
    self._run()
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 255, in _run
    self._read_loop(resp)
  File "/usr/local/lib/python2.7/site-packages/tweepy/streaming.py", line 298, in _read_loop
    line = buf.read_line().strip()
AttributeError: 'NoneType' object has no attribute 'strip'
/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.
  InsecurePlatformWarning
Info: Sourcing environment configuration script /etc/flume-ng/conf/flume-env.sh
Info: Including Hadoop libraries found via (/opt/cloudera/parcels/CDH/lib/hadoop/bin/hadoop) for HDFS access
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/slf4j-log4j12.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/slf4j-api-1.7.5.jar from classpath
Info: Including HBASE libraries found via (/usr/bin/hbase) for HBASE access
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/slf4j-log4j12.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/slf4j-log4j12.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH/lib/hadoop/lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH/lib/hadoop/lib/slf4j-log4j12.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/slf4j-api-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar from classpath
Info: Excluding /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/slf4j-log4j12.jar from classpath
Info: Including Hive libraries found via (/opt/cloudera/parcels/CDH/lib/hive) for Hive access
+ exec /opt/jdk1.7.0_79/bin/java -Xms2048m -Xmx2048m -Xss1024m -Xmn1024m -Dflume.root.logger=INFO,console -cp '/etc/flume-ng/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/usr/lib/hadoop/flume-sources-1.0-SNAPSHOT.jar:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client-0.20:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//libexec:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/spark-1.3.0-cdh5.4.0-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/ant-contrib-1.0b3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro-compiler.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hadoop-fairscheduler-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jdiff:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-2.1:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.2.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//bin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//CHANGES.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//cloudera:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//conf:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//contrib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//example-confs:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//include:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//lib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//README.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../conf:/opt/jdk1.7.0_79/lib/tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/..:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-codec-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-daemon-1.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-logging-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-math-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/core-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/guava-12.0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-annotations-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-annotations-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-checkstyle-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-client-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-common-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-common-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-examples-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop2-compat-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop2-compat-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop-compat-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop-compat-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-it-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-it-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-prefix-tree-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-protocol-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-rest-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-server-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-server-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-shell-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-testing-util-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-thrift-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jaxb-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jettison-1.3.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-sslengine-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/joni-2.1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/netty-3.6.6.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/zookeeper.jar:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client-0.20:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//libexec:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/spark-1.3.0-cdh5.4.0-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/ant-contrib-1.0b3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro-compiler.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hadoop-fairscheduler-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jdiff:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-2.1:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.2.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//bin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//CHANGES.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//cloudera:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//conf:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//contrib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//example-confs:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//include:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//lib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//README.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//webapps:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/bin:/opt/cloudera/parcels/CDH/lib/hadoop/client:/opt/cloudera/parcels/CDH/lib/hadoop/client-0.20:/opt/cloudera/parcels/CDH/lib/hadoop/cloudera:/opt/cloudera/parcels/CDH/lib/hadoop/etc:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib:/opt/cloudera/parcels/CDH/lib/hadoop/libexec:/opt/cloudera/parcels/CDH/lib/hadoop/LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop/NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-tools.jar:/opt/cloudera/parcels/CDH/lib/hadoop/sbin:/opt/cloudera/parcels/CDH/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/zookeeper-3.4.5-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/log4j-1.2.16.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/netty-3.2.2.Final.jar:/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/antlr-2.7.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/antlr-runtime-3.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/apache-mime4j-core-0.7.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/apache-mime4j-dom-0.7.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/argparse4j-0.4.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-commons-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-debug-all-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/aspectjrt-1.6.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/bcmail-jdk15-1.45.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/bcprov-jdk15-1.45.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/boilerpipe-1.1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-fileupload-1.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/concurrentlinkedhashmap-lru-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/config-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/dom4j-1.6.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/fontbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hppc-0.5.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpmime-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/isoparser-1.0-RC-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-annotations-2.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-core-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-databind-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/javax.servlet-3.0.0.v201112011016.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jcl-over-slf4j-1.7.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jdom-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jempbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-continuation-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-deploy-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-http-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-io-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-jmx-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-security-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-server-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-servlet-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-util-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-webapp-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-xml-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jhighlight-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/joda-time-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/juniversalchardet-1.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-hadoop-compatibility.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-rcfile.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-sequencefile.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-json.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-maxmind.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-metrics-servlets.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-saxon.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-solr-cell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-solr-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-tika-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-tika-decompress.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-twitter.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-useragent.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-kuromoji.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-phonetic.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-codecs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-expressions.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-grouping.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-highlighter.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-join.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-memory.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-misc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-queries.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-queryparser.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-spatial.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-suggest.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/maxmind-db-1.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metadata-extractor-2.6.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-core-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-healthchecks-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-json-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-jvm-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-servlets-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/netcdf-4.2-min.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/noggit-0.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/org.restlet-2.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/org.restlet.ext.servlet-2.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/pdfbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-ooxml-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-ooxml-schemas-3.10.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-scratchpad-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/rome-0.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/Saxon-HE-9.5.1-5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/snakeyaml-1.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-cell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-solrj.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/spatial4j-0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tagsoup-1.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-core-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-parsers-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-xmp-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/ua-parser-1.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-core-0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-core-0.1-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-tika-0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/wstx-asl-3.2.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmlbeans-2.6.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmpcore-5.1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/*' -Djava.library.path=:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/lib/native org.apache.flume.node.Application --conf-file /etc/flume-ng/conf/flume-user-tweets.conf --name user-tweets
2015-05-15 22:02:05,908 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start(PollingPropertiesFileConfigurationProvider.java:61)] Configuration provider starting
2015-05-15 22:02:05,917 (conf-file-poller-0) [INFO - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:133)] Reloading configuration file:/etc/flume-ng/conf/flume-user-tweets.conf
2015-05-15 22:02:05,926 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,933 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,934 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:931)] Added sinks: hdfs-sink-2 Agent: user-tweets
2015-05-15 22:02:05,935 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,935 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,935 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,935 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,935 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty(FlumeConfiguration.java:1017)] Processing:hdfs-sink-2
2015-05-15 22:02:05,960 (conf-file-poller-0) [INFO - org.apache.flume.conf.FlumeConfiguration.validateConfiguration(FlumeConfiguration.java:141)] Post-validation flume configuration contains configuration for agents: [user-tweets]
2015-05-15 22:02:05,963 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:145)] Creating channels
2015-05-15 22:02:05,974 (conf-file-poller-0) [INFO - org.apache.flume.channel.DefaultChannelFactory.create(DefaultChannelFactory.java:42)] Creating instance of channel hdfs-channel-2 type memory
2015-05-15 22:02:05,979 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.loadChannels(AbstractConfigurationProvider.java:200)] Created channel hdfs-channel-2
2015-05-15 22:02:05,980 (conf-file-poller-0) [INFO - org.apache.flume.source.DefaultSourceFactory.create(DefaultSourceFactory.java:41)] Creating instance of source kafka-source-2, type org.apache.flume.source.kafka.KafkaSource
2015-05-15 22:02:05,985 (conf-file-poller-0) [INFO - org.apache.flume.source.kafka.KafkaSourceUtil.getKafkaProperties(KafkaSourceUtil.java:37)] context={ parameters:{topic=user-tweets, zookeeperConnect=localhost:2181, batchSize=1000, channels=hdfs-channel-2, type=org.apache.flume.source.kafka.KafkaSource} }
2015-05-15 22:02:06,001 (conf-file-poller-0) [INFO - org.apache.flume.sink.DefaultSinkFactory.create(DefaultSinkFactory.java:42)] Creating instance of sink: hdfs-sink-2, type: hdfs
2015-05-15 22:02:06,015 (conf-file-poller-0) [INFO - org.apache.flume.node.AbstractConfigurationProvider.getConfiguration(AbstractConfigurationProvider.java:114)] Channel hdfs-channel-2 connected to [kafka-source-2, hdfs-sink-2]
2015-05-15 22:02:06,018 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:138)] Starting new configuration:{ sourceRunners:{kafka-source-2=PollableSourceRunner: { source:org.apache.flume.source.kafka.KafkaSource{name:kafka-source-2,state:IDLE} counterGroup:{ name:null counters:{} } }} sinkRunners:{hdfs-sink-2=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@67d1a6b3 counterGroup:{ name:null counters:{} } }} channels:{hdfs-channel-2=org.apache.flume.channel.MemoryChannel{name: hdfs-channel-2}} }
2015-05-15 22:02:06,018 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:145)] Starting Channel hdfs-channel-2
2015-05-15 22:02:06,073 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:120)] Monitored counter group for type: CHANNEL, name: hdfs-channel-2: Successfully registered new MBean.
2015-05-15 22:02:06,074 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:96)] Component type: CHANNEL, name: hdfs-channel-2 started
2015-05-15 22:02:06,074 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:173)] Starting Sink hdfs-sink-2
2015-05-15 22:02:06,077 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:184)] Starting Source kafka-source-2
2015-05-15 22:02:06,077 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.kafka.KafkaSource.start(KafkaSource.java:196)] Starting org.apache.flume.source.kafka.KafkaSource{name:kafka-source-2,state:IDLE}...
2015-05-15 22:02:06,078 (lifecycleSupervisor-1-1) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:120)] Monitored counter group for type: SINK, name: hdfs-sink-2: Successfully registered new MBean.
2015-05-15 22:02:06,078 (lifecycleSupervisor-1-1) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:96)] Component type: SINK, name: hdfs-sink-2 started
2015-05-15 22:02:06,546 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Verifying properties
2015-05-15 22:02:06,645 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property auto.commit.enable is overridden to false
2015-05-15 22:02:06,645 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property consumer.timeout.ms is overridden to 10
2015-05-15 22:02:06,646 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property group.id is overridden to flume
2015-05-15 22:02:06,646 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property zookeeper.connect is overridden to localhost:2181
2015-05-15 22:02:06,719 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Connecting to zookeeper instance at localhost:2181
2015-05-15 22:02:06,752 (ZkClient-EventThread-20-localhost:2181) [INFO - org.I0Itec.zkclient.ZkEventThread.run(ZkEventThread.java:64)] Starting ZkClient event thread.
2015-05-15 22:02:06,775 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:zookeeper.version=3.4.5-cdh5.4.0--1, built on 04/21/2015 19:11 GMT
2015-05-15 22:02:06,775 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:host.name=pti-base.insafanalytics.com
2015-05-15 22:02:06,776 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.version=1.7.0_79
2015-05-15 22:02:06,776 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.vendor=Oracle Corporation
2015-05-15 22:02:06,776 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.home=/opt/jdk1.7.0_79/jre
2015-05-15 22:02:06,777 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.class.path=/etc/flume-ng/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/groovy-all-2.1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/calcite-avatica-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-serde.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/datanucleus-core-3.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-kafka-channel-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-scribe-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-exec.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/kite-data-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/opencsv-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-configuration-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-databind-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/bonecp-0.7.1.RELEASE.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-elasticsearch-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/avro-ipc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/datanucleus-api-jdo-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-spillable-memory-channel-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/xercesImpl-2.9.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/curator-client-2.6.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/calcite-linq4j-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-dataset-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/xml-apis-1.3.04.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/ant-launcher-1.8.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/slf4j-api-1.7.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/mapdb-0.9.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/async-1.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jopt-simple-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-shims-scheduler.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-thrift-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-dbcp-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/antlr-runtime-3.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/xalan-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/serializer-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/libfb303-0.9.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-hbase-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/ST4-4.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/antlr-2.7.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/asynchbase-1.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/twitter4j-media-support-3.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-tools-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/irclib-1.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/janino-2.7.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-shims-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jta-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/twitter4j-stream-3.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jets3t-0.6.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/kafka_2.10-0.8.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/metrics-core-2.2.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-node-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/eigenbase-properties-1.1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/stringtemplate-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/curator-framework-2.6.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-annotations-2.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-hdfs-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-jdbc-channel-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/stax-api-1.0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-core-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-kafka-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-hive-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-shims-0.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/calcite-core-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/datanucleus-rdbms-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-codec-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/mina-core-2.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-kafka-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-metastore.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-core-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-servlet-1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-jexl-2.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/velocity-1.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/twitter4j-core-3.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/zkclient-0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/kite-hadoop-compatibility.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-file-channel-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/curator-recipes-2.6.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-log4jappender-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-compiler-2.7.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/joda-time-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/libthrift-0.9.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jdo-api-3.0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-avro-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/ant-1.8.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-twitter-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/apache-log4j-extras-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-irc-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/derby-10.8.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-sdk-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-shims.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/servlet-api-2.5-20110124.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/kite-data-hive.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-morphline-solr-sink-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/kite-data-hbase.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/scala-library-2.10.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-core-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/hive-ant.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-pool-1.5.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-jms-source-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-auth-1.5.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/flume-ng-embedded-agent-1.5.0-cdh5.4.0.jar:/usr/lib/hadoop/flume-sources-1.0-SNAPSHOT.jar:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client-0.20:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//libexec:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/spark-1.3.0-cdh5.4.0-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/ant-contrib-1.0b3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro-compiler.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hadoop-fairscheduler-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jdiff:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-2.1:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.2.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//bin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//CHANGES.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//cloudera:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//conf:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//contrib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//example-confs:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//include:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//lib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//README.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../conf:/opt/jdk1.7.0_79/lib/tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/..:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-codec-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-daemon-1.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-logging-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-math-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/core-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/disruptor-3.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/guava-12.0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-annotations-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-annotations-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-checkstyle-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-client-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-common-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-common-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-examples-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop2-compat-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop2-compat-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop-compat-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-hadoop-compat-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-it-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-it-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-prefix-tree-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-protocol-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-rest-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-server-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-server-1.0.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-shell-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-testing-util-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hbase-thrift-1.0.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/high-scale-lib-1.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/htrace-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jamon-runtime-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jaxb-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jcodings-1.0.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jettison-1.3.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-sslengine-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/joni-2.1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jruby-complete-1.6.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-2.1-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/libthrift-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/metrics-core-2.2.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/netty-3.2.4.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/netty-3.6.6.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hbase/bin/../lib/zookeeper.jar:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//client-0.20:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-aws.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-common-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//hadoop-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//libexec:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-cascading.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-format-sources.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-pig.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-protobuf.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-thrift.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//parquet-tools.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//hadoop-hdfs-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//sbin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//webapps:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/aopalliance-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/guice-servlet-3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/javax.inject-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-client-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-guice-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/leveldbjni-all-1.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/spark-1.3.0-cdh5.4.0-yarn-shuffle.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//etc:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-api.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-client.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-registry.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/ant-contrib-1.0b3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro-compiler.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hadoop-fairscheduler-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/hsqldb-1.8.0.10.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jdiff:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-2.1:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/kfs-0.2.LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.2.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//bin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//CHANGES.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//cloudera:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//conf:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//contrib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//example-confs:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-ant-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-core-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-examples-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-test-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-2.6.0-mr1-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//hadoop-tools-mr1.jar:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//include:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//lib:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//README.txt:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//sbin:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//webapps:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/bin:/opt/cloudera/parcels/CDH/lib/hadoop/client:/opt/cloudera/parcels/CDH/lib/hadoop/client-0.20:/opt/cloudera/parcels/CDH/lib/hadoop/cloudera:/opt/cloudera/parcels/CDH/lib/hadoop/etc:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-annotations-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-annotations.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-auth-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-auth.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-aws-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-aws.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-2.6.0-cdh5.4.0-tests.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-common-tests.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-nfs-2.6.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/hadoop-nfs.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib:/opt/cloudera/parcels/CDH/lib/hadoop/libexec:/opt/cloudera/parcels/CDH/lib/hadoop/LICENSE.txt:/opt/cloudera/parcels/CDH/lib/hadoop/NOTICE.txt:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-cascading.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-column.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-common.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-encoding.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format-javadoc.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-format-sources.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-generator.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-hadoop.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-jackson.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-pig-bundle.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-pig.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-protobuf.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-scala_2.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-scrooge_2.10.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-test-hadoop2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-thrift.jar:/opt/cloudera/parcels/CDH/lib/hadoop/parquet-tools.jar:/opt/cloudera/parcels/CDH/lib/hadoop/sbin:/opt/cloudera/parcels/CDH/lib/hadoop/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/api-util-1.0.0-M20.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/aws-java-sdk-1.7.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-httpclient-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/hamcrest-core-1.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/hue-plugins-3.7.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jackson-xc-1.8.8.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jaxb-api-2.2.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-json-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jets3t-0.9.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jettison-1.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsp-api-2.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/mockito-all-1.8.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/native:/opt/cloudera/parcels/CDH/lib/hadoop/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/stax-api-1.0-2.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hadoop/lib/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/bin:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/cloudera:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/LICENSE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/NOTICE.txt:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/zookeeper-3.4.5-cdh5.4.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/zookeeper.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/jline-2.11.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/log4j-1.2.16.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/bin/../lib/zookeeper/lib/netty-3.2.2.Final.jar:/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/antlr-2.7.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/antlr-runtime-3.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/apache-mime4j-core-0.7.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/apache-mime4j-dom-0.7.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/argparse4j-0.4.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-commons-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/asm-debug-all-4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/aspectjrt-1.6.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/bcmail-jdk15-1.45.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/bcprov-jdk15-1.45.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/boilerpipe-1.1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-el-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-fileupload-1.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-math3-3.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/commons-net-3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/concurrentlinkedhashmap-lru-1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/config-1.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-client-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-framework-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/curator-recipes-2.7.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/dom4j-1.6.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/fontbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/gson-2.2.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/guava-11.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-annotations.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-auth.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hadoop-hdfs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/hppc-0.5.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/htrace-core-3.0.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/httpmime-4.2.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/isoparser-1.0-RC-1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-annotations-2.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-core-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-core-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-databind-2.3.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jackson-mapper-asl-1.8.8.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/javax.servlet-3.0.0.v201112011016.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jcl-over-slf4j-1.7.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jdom-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jempbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jersey-core-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jersey-server-1.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-continuation-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-deploy-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-http-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-io-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-jmx-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-security-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-server-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-servlet-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-util-6.1.26.cloudera.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-util-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-webapp-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jetty-xml-8.1.10.v20130312.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jhighlight-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/joda-time-1.6.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jsch-0.1.42.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/jsr305-1.3.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/juniversalchardet-1.0.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-hadoop-compatibility.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-rcfile.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-hadoop-sequencefile.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-json.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-maxmind.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-metrics-servlets.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-saxon.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-solr-cell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-solr-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-tika-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-tika-decompress.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-twitter.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/kite-morphlines-useragent.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/log4j-1.2.17.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-kuromoji.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-analyzers-phonetic.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-codecs.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-expressions.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-grouping.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-highlighter.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-join.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-memory.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-misc.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-queries.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-queryparser.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-spatial.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/lucene-suggest.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/maxmind-db-1.0.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metadata-extractor-2.6.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-core-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-healthchecks-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-json-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-jvm-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/metrics-servlets-3.0.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/netcdf-4.2-min.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/netty-3.6.2.Final.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/noggit-0.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/org.restlet-2.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/org.restlet.ext.servlet-2.1.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-avro.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-column.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-common.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-encoding.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-format.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-generator.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-hadoop.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/parquet-jackson.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/pdfbox-1.8.4.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-ooxml-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-ooxml-schemas-3.10.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/poi-scratchpad-3.10-beta2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/protobuf-java-2.5.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/rome-0.9.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/Saxon-HE-9.5.1-5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/snakeyaml-1.10.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-cell.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-core.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/solr-solrj.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/spatial4j-0.4.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tagsoup-1.2.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-core-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-parsers-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/tika-xmp-1.5.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/ua-parser-1.3.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-core-0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-core-0.1-tests.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/vorbis-java-tika-0.1.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/wstx-asl-3.2.7.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmlbeans-2.6.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmlenc-0.52.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xmpcore-5.1.2.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/../search/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-jdbc-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/groovy-all-2.1.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-hadoop2-compat.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/calcite-avatica-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/paranamer-2.3.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jpam-1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/parquet-hadoop-bundle.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/junit-4.11.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jetty-all-7.6.0.v20120127.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/high-scale-lib-1.1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-exec.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/plexus-utils-1.5.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/opencsv-2.3.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-exec-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-hadoop-compat.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-common.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/log4j-1.2.16.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-jdbc-1.1.0-cdh5.4.0-standalone.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jcommander-1.32.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/curator-client-2.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/calcite-linq4j-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-client.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-hbase-handler-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-codec-1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-service-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-digester-1.8.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/datanucleus-rdbms-3.2.9.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-metastore-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-scheduler.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-dbcp-1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/antlr-runtime-3.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-testutils-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/libfb303-0.9.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/logredactor-1.0.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/ST4-4.0.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/derby-10.11.1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/ant-launcher-1.9.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jsr305-3.0.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/regexp-1.3.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/antlr-2.7.7.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-hwi-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-collections-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/accumulo-start-1.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/servlet-api-2.5.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/janino-2.7.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-common.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-jdbc.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jersey-server-1.14.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-common.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-testutils.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/zookeeper.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jta-1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-httpclient-3.0.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-ant-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-compress-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/activation-1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/httpcore-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/asm-3.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/apache-log4j-extras-1.2.17.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-scheduler-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/xz-1.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/maven-scm-api-1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/oro-2.0.8.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/eigenbase-properties-1.1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/stringtemplate-3.2.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/avro.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/curator-framework-2.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-accumulo-handler-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-cli-1.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/mail-1.4.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/stax-api-1.0.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-0.23.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/calcite-core-1.0.0-incubating.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-hwi.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/guava-14.0.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-jdbc-standalone.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-beanutils-1.7.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jackson-jaxrs-1.9.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/httpclient-4.2.5.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jackson-xc-1.9.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-metastore.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-common-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-logging-1.1.3.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jersey-servlet-1.14.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/maven-scm-provider-svnexe-1.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/asm-tree-3.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-lang-2.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/super-csv-2.2.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-hbase-handler.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jline-2.12.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-protocol.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-cli-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-compiler-2.7.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/datanucleus-core-3.2.10.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/velocity-1.5.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-configuration-1.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/accumulo-trace-1.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/libthrift-0.9.2.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/accumulo-fate-1.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims-0.23-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/snappy-java-1.0.4.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jdo-api-3.0.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-beanutils-core-1.8.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/accumulo-core-1.6.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/datanucleus-api-jdo-3.2.6.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/ant-1.9.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-cli.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-vfs2-2.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-shims.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hamcrest-core-1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-accumulo-handler.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-math-2.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hbase-server.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/tempus-fugit-1.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-ant.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-pool-1.5.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/commons-io-2.4.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-beeline-1.1.0-cdh5.4.0.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-service.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-beeline.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/htrace-core.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/asm-commons-3.1.jar:/opt/cloudera/parcels/CDH/lib/hive/lib/hive-common-1.1.0-cdh5.4.0.jar
2015-05-15 22:02:06,788 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.library.path=:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/lib/native:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/lib/native
2015-05-15 22:02:06,788 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.io.tmpdir=/tmp
2015-05-15 22:02:06,788 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:java.compiler=<NA>
2015-05-15 22:02:06,789 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:os.name=Linux
2015-05-15 22:02:06,789 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:os.arch=amd64
2015-05-15 22:02:06,789 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:os.version=2.6.32-504.12.2.el6.x86_64
2015-05-15 22:02:06,790 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:user.name=root
2015-05-15 22:02:06,790 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:user.home=/root
2015-05-15 22:02:06,790 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.Environment.logEnv(Environment.java:100)] Client environment:user.dir=/root/kafka-producer
2015-05-15 22:02:06,793 (lifecycleSupervisor-1-0) [INFO - org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:438)] Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@2edd36f3
2015-05-15 22:02:06,971 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-15 22:02:06,985 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2015-05-15 22:02:07,094 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-15 22:02:07,096 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:852)] Socket connection established to localhost/127.0.0.1:2181, initiating session
2015-05-15 22:02:07,149 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1235)] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14d5867a7190000, negotiated timeout = 6000
2015-05-15 22:02:07,154 (lifecycleSupervisor-1-0-EventThread) [INFO - org.I0Itec.zkclient.ZkClient.processStateChanged(ZkClient.java:449)] zookeeper state changed (SyncConnected)
2015-05-15 22:02:07,326 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], begin registering consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 in ZK
2015-05-15 22:02:07,501 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], end registering consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 in ZK
2015-05-15 22:02:07,510 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9_watcher_executor) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], starting watcher executor thread for consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9
2015-05-15 22:02:07,584 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], begin rebalancing consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 try #0
2015-05-15 22:02:08,379 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [ConsumerFetcherManager-1431709327177] Stopping leader finder thread
2015-05-15 22:02:08,380 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [ConsumerFetcherManager-1431709327177] Stopping all fetchers
2015-05-15 22:02:08,384 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [ConsumerFetcherManager-1431709327177] All connections stopped
2015-05-15 22:02:08,386 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Cleared all relevant queues for this fetcher
2015-05-15 22:02:08,392 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Cleared the data chunks in all the consumer message iterators
2015-05-15 22:02:08,393 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Committing all offsets after clearing the fetcher queues
2015-05-15 22:02:08,395 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Releasing partition ownership
2015-05-15 22:02:08,402 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 rebalancing the following partitions: ArrayBuffer(0) for topic user-tweets with consumers: List(flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0)
2015-05-15 22:02:08,409 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0 attempting to claim partition 0
2015-05-15 22:02:08,438 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0 successfully owned partition 0 for topic user-tweets
2015-05-15 22:02:08,441 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Updating the cache
2015-05-15 22:02:08,450 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], Consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 selected partitions : user-tweets:0: fetched offset = 81371: consumed offset = 81371
2015-05-15 22:02:08,480 (lifecycleSupervisor-1-0) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9], end rebalancing consumer flume_pti-base.insafanalytics.com-1431709326715-a87037b9 try #0
2015-05-15 22:02:08,480 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread], Starting 
2015-05-15 22:02:08,486 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.kafka.KafkaSource.start(KafkaSource.java:224)] Kafka source kafka-source-2 started.
2015-05-15 22:02:08,488 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.register(MonitoredCounterGroup.java:120)] Monitored counter group for type: SOURCE, name: kafka-source-2: Successfully registered new MBean.
2015-05-15 22:02:08,489 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.start(MonitoredCounterGroup.java:96)] Component type: SOURCE, name: kafka-source-2 started
2015-05-15 22:02:08,581 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Verifying properties
2015-05-15 22:02:08,582 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property client.id is overridden to flume
2015-05-15 22:02:08,582 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property metadata.broker.list is overridden to pti-base.insafanalytics.com:9092,pti-node-2.insafanalytics.com:9092
2015-05-15 22:02:08,583 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Property request.timeout.ms is overridden to 30000
2015-05-15 22:02:08,661 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Fetching metadata from broker id:65,host:pti-base.insafanalytics.com,port:9092 with correlation id 0 for 1 topic(s) Set(user-tweets)
2015-05-15 22:02:08,666 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Connected to pti-base.insafanalytics.com:9092 for producing
2015-05-15 22:02:08,808 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] Disconnecting from pti-base.insafanalytics.com:9092
2015-05-15 22:02:08,859 (ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67], Starting 
2015-05-15 22:02:08,875 (flume_pti-base.insafanalytics.com-1431709326715-a87037b9-leader-finder-thread) [INFO - kafka.utils.Logging$class.info(Logging.scala:68)] [ConsumerFetcherManager-1431709327177] Added fetcher for partitions ArrayBuffer([[user-tweets,0], initOffset 81371 to broker id:67,host:pti-node-2.insafanalytics.com,port:9092] )
2015-05-15 22:03:08,118 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-15 22:03:08,524 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388119.tmp
2015-05-15 22:36:13,825 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388119.tmp
2015-05-15 22:36:13,907 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388119.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388119
2015-05-15 22:36:14,007 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388120.tmp
2015-05-15 22:50:54,541 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388120.tmp
2015-05-15 22:50:54,626 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388120.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388120
2015-05-15 22:50:54,713 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388121.tmp
2015-05-15 23:06:14,287 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388121.tmp
2015-05-15 23:06:14,347 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388121.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388121
2015-05-15 23:06:14,392 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388122.tmp
2015-05-15 23:21:16,753 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388122.tmp
2015-05-15 23:21:16,817 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388122.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388122
2015-05-15 23:21:16,914 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388123.tmp
2015-05-15 23:28:16,630 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388123.tmp
2015-05-15 23:28:16,707 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388123.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388123
2015-05-15 23:28:16,792 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388124.tmp
2015-05-15 23:38:23,718 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388124.tmp
2015-05-15 23:38:23,789 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388124.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388124
2015-05-15 23:38:23,849 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388125.tmp
2015-05-15 23:58:03,396 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388125.tmp
2015-05-15 23:58:03,476 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388125.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388125
2015-05-15 23:58:03,553 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388126.tmp
2015-05-16 00:00:01,564 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-16 00:00:01,611 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401565.tmp
2015-05-16 00:28:47,001 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401565.tmp
2015-05-16 00:28:47,050 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401565.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401565
2015-05-16 00:28:47,130 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401566.tmp
2015-05-16 00:49:35,867 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401566.tmp
2015-05-16 00:49:35,923 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401566.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401566
2015-05-16 00:49:36,006 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401567.tmp
2015-05-16 00:59:59,534 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388126.tmp at 1431719999533
2015-05-16 00:59:59,536 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388126.tmp
2015-05-16 00:59:59,584 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388126.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150515/user_tweets.1431709388126
2015-05-16 00:59:59,591 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-16 01:13:19,972 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401567.tmp
2015-05-16 01:13:20,014 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401567.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401567
2015-05-16 01:13:20,063 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401568.tmp
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/avro-tools-1.7.6-cdh5.4.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/05/15 16:33:42 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
15/05/15 16:33:43 INFO SecurityManager: Changing view acls to: root
15/05/15 16:33:43 INFO SecurityManager: Changing modify acls to: root
15/05/15 16:33:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/05/15 16:33:44 INFO Slf4jLogger: Slf4jLogger started
15/05/15 16:33:44 INFO Remoting: Starting remoting
15/05/15 16:33:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324]
15/05/15 16:33:44 INFO Utils: Successfully started service 'sparkWorker' on port 46324.
15/05/15 16:33:45 INFO Worker: Starting Spark worker pti-base.insafanalytics.com:46324 with 2 cores, 1024.0 MB RAM
15/05/15 16:33:45 INFO Worker: Running Spark version 1.3.0
15/05/15 16:33:45 INFO Worker: Spark home: /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark
15/05/15 16:33:45 INFO Server: jetty-8.y.z-SNAPSHOT
15/05/15 16:33:45 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8081
15/05/15 16:33:45 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
15/05/15 16:33:45 INFO WorkerWebUI: Started WorkerWebUI at http://pti-base.insafanalytics.com:8081
15/05/15 16:33:45 INFO Worker: Connecting to master akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079/user/Master...
15/05/15 16:33:46 INFO Worker: Successfully registered with master spark://pti-base.insafanalytics.com:7079
2015-05-16 01:36:59,078 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401568.tmp
2015-05-16 01:36:59,129 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401568.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401568
2015-05-16 01:36:59,221 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401569.tmp
15/05/15 16:44:23 INFO Worker: Asked to launch executor app-20150515164423-0001/1 for PTITwitterStream
15/05/15 16:44:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=48644" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:48644/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150515164423-0001" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
15/05/15 16:47:17 INFO Worker: Asked to kill executor app-20150515164423-0001/1
15/05/15 16:47:17 INFO ExecutorRunner: Runner thread for executor app-20150515164423-0001/1 interrupted
15/05/15 16:47:17 INFO ExecutorRunner: Killing process!
15/05/15 16:47:17 INFO Worker: Executor app-20150515164423-0001/1 finished with state KILLED exitStatus 1
15/05/15 16:47:17 INFO Worker: Cleaning up local directories for application app-20150515164423-0001
15/05/15 16:47:17 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A40265-2#1909891788] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/15 16:47:17 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57778
]
15/05/15 16:47:17 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57778
]
15/05/15 16:47:17 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57778]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57778
]
15/05/15 16:48:26 INFO Worker: Asked to launch executor app-20150515164826-0002/1 for PTITwitterStream
15/05/15 16:48:26 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=56371" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:56371/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150515164826-0002" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-16 02:18:37,308 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401569.tmp
2015-05-16 02:18:37,349 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401569.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401569
2015-05-16 02:18:37,430 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401570.tmp
2015-05-16 03:00:29,556 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401570.tmp
2015-05-16 03:00:29,608 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401570.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401570
2015-05-16 03:00:29,660 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401571.tmp
2015-05-16 05:29:30,510 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401571.tmp
2015-05-16 05:29:30,569 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401571.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401571
2015-05-16 05:29:30,619 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401572.tmp
2015-05-16 07:49:51,882 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401572.tmp
2015-05-16 07:49:51,991 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401572.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401572
2015-05-16 07:49:52,084 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401573.tmp
2015-05-16 10:18:31,727 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401573.tmp
2015-05-16 10:18:31,767 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401573.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401573
2015-05-16 10:18:31,823 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401574.tmp
2015-05-16 10:40:38,833 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401574.tmp
2015-05-16 10:40:38,867 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401574.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401574
2015-05-16 10:40:38,908 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401575.tmp
2015-05-16 11:01:46,736 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401575.tmp
2015-05-16 11:01:46,784 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401575.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401575
2015-05-16 11:01:46,873 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401576.tmp
15/05/16 02:12:04 INFO Worker: Asked to kill executor app-20150515164826-0002/1
15/05/16 02:12:04 INFO ExecutorRunner: Runner thread for executor app-20150515164826-0002/1 interrupted
15/05/16 02:12:04 INFO ExecutorRunner: Killing process!
15/05/16 02:12:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150515164826-0002/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/16 02:12:04 INFO Worker: Executor app-20150515164826-0002/1 finished with state KILLED exitStatus 1
15/05/16 02:12:04 INFO Worker: Cleaning up local directories for application app-20150515164826-0002
15/05/16 02:12:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A40496-6#2062300126] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/16 02:12:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57536
]
15/05/16 02:12:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57536
]
15/05/16 02:12:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57536]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57536
]
2015-05-16 11:32:44,294 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401576.tmp
2015-05-16 11:32:44,340 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401576.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401576
2015-05-16 11:32:44,399 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401577.tmp
15/05/16 02:45:25 INFO Worker: Asked to launch executor app-20150516024524-0003/1 for PTITwitterStream
15/05/16 02:45:25 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=36607" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:36607/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150516024524-0003" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-16 11:55:57,293 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401577.tmp
2015-05-16 11:55:57,331 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401577.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401577
2015-05-16 11:55:57,406 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401578.tmp
2015-05-16 12:15:35,236 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401578.tmp
2015-05-16 12:15:35,288 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401578.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401578
2015-05-16 12:15:35,371 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401579.tmp
2015-05-16 12:36:31,174 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401579.tmp
2015-05-16 12:36:31,212 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401579.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401579
2015-05-16 12:36:31,301 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401580.tmp
2015-05-16 12:47:08,286 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401580.tmp
2015-05-16 12:47:08,335 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401580.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401580
2015-05-16 12:47:08,384 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401581.tmp
2015-05-16 12:54:42,079 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401581.tmp
2015-05-16 12:54:42,127 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401581.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401581
2015-05-16 12:54:42,215 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401582.tmp
2015-05-16 13:00:18,719 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401582.tmp
2015-05-16 13:00:18,763 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401582.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401582
2015-05-16 13:00:18,827 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401583.tmp
2015-05-16 13:07:38,528 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401583.tmp
2015-05-16 13:07:38,582 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401583.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401583
2015-05-16 13:07:38,667 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401584.tmp
2015-05-16 13:16:33,536 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401584.tmp
2015-05-16 13:16:33,575 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401584.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401584
2015-05-16 13:16:33,623 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401585.tmp
2015-05-16 13:26:27,613 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401585.tmp
2015-05-16 13:26:27,652 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401585.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401585
2015-05-16 13:26:27,731 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401586.tmp
2015-05-16 13:33:29,434 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401586.tmp
2015-05-16 13:33:29,474 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401586.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401586
2015-05-16 13:33:29,528 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401587.tmp
2015-05-16 13:40:47,291 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401587.tmp
2015-05-16 13:40:47,351 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401587.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401587
2015-05-16 13:40:47,441 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401588.tmp
2015-05-16 13:50:12,328 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401588.tmp
2015-05-16 13:50:12,361 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401588.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401588
2015-05-16 13:50:12,404 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401589.tmp
2015-05-16 14:15:03,468 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401589.tmp
2015-05-16 14:15:03,494 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401589.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401589
2015-05-16 14:15:03,576 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401590.tmp
2015-05-16 14:31:28,006 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401590.tmp
2015-05-16 14:31:28,043 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401590.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401590
2015-05-16 14:31:28,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401591.tmp
2015-05-16 15:10:06,954 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401591.tmp
2015-05-16 15:10:07,000 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401591.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401591
2015-05-16 15:10:07,091 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401592.tmp
2015-05-16 15:58:52,316 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401592.tmp
2015-05-16 15:58:52,370 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401592.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401592
2015-05-16 15:58:52,477 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401593.tmp
2015-05-16 16:28:06,783 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401593.tmp
2015-05-16 16:28:06,822 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401593.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401593
2015-05-16 16:28:06,907 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401594.tmp
2015-05-16 16:44:53,364 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401594.tmp
2015-05-16 16:44:53,400 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401594.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401594
2015-05-16 16:44:53,483 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401595.tmp
2015-05-16 17:01:18,353 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401595.tmp
2015-05-16 17:01:18,407 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401595.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401595
2015-05-16 17:01:18,504 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401596.tmp
2015-05-16 17:49:01,887 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401596.tmp
2015-05-16 17:49:01,936 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401596.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401596
2015-05-16 17:49:01,987 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401597.tmp
15/05/16 09:54:04 INFO Worker: Asked to kill executor app-20150516024524-0003/1
15/05/16 09:54:04 INFO ExecutorRunner: Runner thread for executor app-20150516024524-0003/1 interrupted
15/05/16 09:54:04 INFO ExecutorRunner: Killing process!
15/05/16 09:54:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150516024524-0003/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/16 09:54:04 INFO Worker: Executor app-20150516024524-0003/1 finished with state KILLED exitStatus 1
15/05/16 09:54:04 INFO Worker: Cleaning up local directories for application app-20150516024524-0003
15/05/16 09:54:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A42982-10#1482002249] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/16 09:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54165
]
15/05/16 09:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54165
]
15/05/16 09:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54165]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54165
]
15/05/16 09:55:06 INFO Worker: Asked to launch executor app-20150516095506-0004/1 for PTITwitterStream
15/05/16 09:55:06 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=41366" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:41366/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150516095506-0004" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-16 19:08:44,075 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401597.tmp
2015-05-16 19:08:44,110 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401597.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401597
2015-05-16 19:08:44,150 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401598.tmp
2015-05-16 20:34:21,901 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401598.tmp
2015-05-16 20:34:21,955 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401598.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401598
2015-05-16 20:34:22,033 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401599.tmp
2015-05-16 20:55:48,025 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401599.tmp
2015-05-16 20:55:48,063 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401599.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401599
2015-05-16 20:55:48,149 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401600.tmp
2015-05-16 21:03:42,939 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401600.tmp
2015-05-16 21:03:42,988 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401600.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401600
2015-05-16 21:03:43,079 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401601.tmp
2015-05-16 21:23:32,808 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401601.tmp
2015-05-16 21:23:32,872 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401601.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401601
2015-05-16 21:23:32,964 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401602.tmp
2015-05-16 22:06:28,184 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401602.tmp
2015-05-16 22:06:28,227 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401602.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401602
2015-05-16 22:06:28,312 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401603.tmp
2015-05-16 22:33:08,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401603.tmp
2015-05-16 22:33:08,614 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401603.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401603
2015-05-16 22:33:08,745 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401604.tmp
2015-05-16 22:42:15,601 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401604.tmp
2015-05-16 22:42:15,644 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401604.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401604
2015-05-16 22:42:15,723 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401605.tmp
2015-05-16 22:48:40,325 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401605.tmp
2015-05-16 22:48:40,359 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401605.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401605
2015-05-16 22:48:40,435 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401606.tmp
2015-05-16 22:52:52,834 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401606.tmp
2015-05-16 22:52:52,878 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401606.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401606
2015-05-16 22:52:52,963 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401607.tmp
2015-05-16 22:55:35,171 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401607.tmp
2015-05-16 22:55:35,204 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401607.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401607
2015-05-16 22:55:35,249 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401608.tmp
2015-05-16 23:00:47,805 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401608.tmp
2015-05-16 23:00:47,852 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401608.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401608
2015-05-16 23:00:47,944 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401609.tmp
2015-05-16 23:12:31,038 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401609.tmp
2015-05-16 23:12:31,084 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401609.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401609
2015-05-16 23:12:31,170 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401610.tmp
2015-05-16 23:23:14,212 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401610.tmp
2015-05-16 23:23:14,260 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401610.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401610
2015-05-16 23:23:14,342 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401611.tmp
2015-05-16 23:50:34,520 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401611.tmp
2015-05-16 23:50:34,580 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401611.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401611
2015-05-16 23:50:34,696 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401612.tmp
2015-05-17 00:00:05,320 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-17 00:00:05,436 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805320.tmp
15/05/16 15:20:13 INFO Worker: Asked to kill executor app-20150516095506-0004/1
15/05/16 15:20:13 INFO ExecutorRunner: Runner thread for executor app-20150516095506-0004/1 interrupted
15/05/16 15:20:13 INFO ExecutorRunner: Killing process!
15/05/16 15:20:13 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150516095506-0004/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/16 15:20:14 INFO Worker: Executor app-20150516095506-0004/1 finished with state KILLED exitStatus 1
15/05/16 15:20:14 INFO Worker: Cleaning up local directories for application app-20150516095506-0004
15/05/16 15:20:14 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A44780-14#-1966968649] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/16 15:20:14 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:58865
]
15/05/16 15:20:14 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:58865
]
15/05/16 15:20:14 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:58865]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:58865
]
15/05/16 15:20:27 INFO Worker: Asked to launch executor app-20150516152027-0005/1 for PTITwitterStream
15/05/16 15:20:27 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=34745" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:34745/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150516152027-0005" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-17 00:23:41,369 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805320.tmp
2015-05-17 00:23:41,425 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805320.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805320
2015-05-17 00:23:41,522 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805321.tmp
2015-05-17 00:40:56,911 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805321.tmp
2015-05-17 00:40:56,958 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805321.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805321
2015-05-17 00:40:57,052 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805322.tmp
2015-05-17 00:59:50,300 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401612.tmp at 1431806390300
2015-05-17 00:59:50,304 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401612.tmp
2015-05-17 00:59:50,346 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401612.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150516/user_tweets.1431716401612
2015-05-17 00:59:50,352 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-17 01:02:07,960 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805322.tmp
2015-05-17 01:02:08,007 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805322.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805322
2015-05-17 01:02:08,103 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805323.tmp
2015-05-17 02:02:54,438 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805323.tmp
2015-05-17 02:02:54,487 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805323.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805323
2015-05-17 02:02:54,568 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805324.tmp
2015-05-17 03:19:11,657 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805324.tmp
2015-05-17 03:19:11,707 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805324.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805324
2015-05-17 03:19:11,793 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805325.tmp
15/05/16 22:07:04 INFO Worker: Asked to kill executor app-20150516152027-0005/1
15/05/16 22:07:04 INFO ExecutorRunner: Runner thread for executor app-20150516152027-0005/1 interrupted
15/05/16 22:07:04 INFO ExecutorRunner: Killing process!
15/05/16 22:07:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150516152027-0005/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/16 22:07:04 INFO Worker: Executor app-20150516152027-0005/1 finished with state KILLED exitStatus 1
15/05/16 22:07:04 INFO Worker: Cleaning up local directories for application app-20150516152027-0005
15/05/16 22:07:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A39343-18#856250597] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/16 22:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54558
]
15/05/16 22:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54558
]
15/05/16 22:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54558]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54558
]
15/05/16 22:07:19 INFO Worker: Asked to launch executor app-20150516220719-0006/1 for PTITwitterStream
15/05/16 22:07:19 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=50005" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:50005/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150516220719-0006" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-17 08:33:20,399 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805325.tmp
2015-05-17 08:33:20,443 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805325.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805325
2015-05-17 08:33:20,492 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805326.tmp
2015-05-17 10:13:20,974 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805326.tmp
2015-05-17 10:13:21,022 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805326.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805326
2015-05-17 10:13:21,115 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805327.tmp
2015-05-17 10:19:39,749 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805327.tmp
2015-05-17 10:19:39,799 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805327.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805327
2015-05-17 10:19:39,846 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805328.tmp
2015-05-17 10:29:35,878 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805328.tmp
2015-05-17 10:29:35,932 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805328.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805328
2015-05-17 10:29:36,021 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805329.tmp
2015-05-17 10:46:19,659 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805329.tmp
2015-05-17 10:46:19,701 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805329.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805329
2015-05-17 10:46:19,774 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805330.tmp
2015-05-17 11:15:57,346 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805330.tmp
2015-05-17 11:15:57,385 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805330.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805330
2015-05-17 11:15:57,446 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805331.tmp
2015-05-17 11:39:59,506 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805331.tmp
2015-05-17 11:39:59,555 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805331.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805331
2015-05-17 11:39:59,631 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805332.tmp
2015-05-17 12:03:43,602 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805332.tmp
2015-05-17 12:03:43,664 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805332.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805332
2015-05-17 12:03:43,741 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805333.tmp
2015-05-17 12:10:57,377 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805333.tmp
2015-05-17 12:10:57,413 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805333.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805333
2015-05-17 12:10:57,518 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805334.tmp
2015-05-17 12:14:54,806 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805334.tmp
2015-05-17 12:14:54,833 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805334.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805334
2015-05-17 12:14:54,913 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805335.tmp
2015-05-17 12:19:12,339 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805335.tmp
2015-05-17 12:19:12,377 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805335.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805335
2015-05-17 12:19:12,460 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805336.tmp
2015-05-17 12:22:18,683 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805336.tmp
2015-05-17 12:22:18,737 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805336.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805336
2015-05-17 12:22:18,818 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805337.tmp
2015-05-17 12:25:38,077 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805337.tmp
2015-05-17 12:25:38,126 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805337.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805337
2015-05-17 12:25:38,218 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805338.tmp
2015-05-17 12:29:19,546 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805338.tmp
2015-05-17 12:29:19,583 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805338.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805338
2015-05-17 12:29:19,654 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805339.tmp
2015-05-17 12:32:38,932 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805339.tmp
2015-05-17 12:32:38,978 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805339.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805339
2015-05-17 12:32:39,062 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805340.tmp
2015-05-17 12:35:20,257 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805340.tmp
2015-05-17 12:35:20,302 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805340.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805340
2015-05-17 12:35:20,388 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805341.tmp
2015-05-17 12:37:38,548 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805341.tmp
2015-05-17 12:37:38,598 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805341.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805341
2015-05-17 12:37:38,697 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805342.tmp
2015-05-17 12:40:45,908 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805342.tmp
2015-05-17 12:40:45,946 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805342.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805342
2015-05-17 12:40:45,993 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805343.tmp
2015-05-17 12:46:24,555 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805343.tmp
2015-05-17 12:46:24,586 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805343.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805343
2015-05-17 12:46:24,651 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805344.tmp
2015-05-17 12:52:55,248 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805344.tmp
2015-05-17 12:52:55,292 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805344.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805344
2015-05-17 12:52:55,359 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805345.tmp
2015-05-17 12:56:50,715 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805345.tmp
2015-05-17 12:56:50,757 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805345.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805345
2015-05-17 12:56:50,826 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805346.tmp
2015-05-17 13:01:44,289 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805346.tmp
2015-05-17 13:01:44,332 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805346.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805346
2015-05-17 13:01:44,408 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805347.tmp
2015-05-17 13:12:33,500 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805347.tmp
2015-05-17 13:12:33,542 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805347.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805347
2015-05-17 13:12:33,628 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805348.tmp
2015-05-17 13:18:28,238 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805348.tmp
2015-05-17 13:18:28,305 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805348.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805348
2015-05-17 13:18:28,390 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805349.tmp
2015-05-17 13:28:42,228 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805349.tmp
2015-05-17 13:28:42,306 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805349.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805349
2015-05-17 13:28:42,385 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805350.tmp
2015-05-17 13:39:18,313 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805350.tmp
2015-05-17 13:39:18,356 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805350.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805350
2015-05-17 13:39:18,431 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805351.tmp
2015-05-17 13:46:49,115 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805351.tmp
2015-05-17 13:46:49,164 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805351.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805351
2015-05-17 13:46:49,245 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805352.tmp
2015-05-17 13:57:51,220 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805352.tmp
2015-05-17 13:57:51,264 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805352.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805352
2015-05-17 13:57:51,348 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805353.tmp
15/05/17 05:03:04 INFO Worker: Asked to kill executor app-20150516220719-0006/1
15/05/17 05:03:04 INFO ExecutorRunner: Runner thread for executor app-20150516220719-0006/1 interrupted
15/05/17 05:03:04 INFO ExecutorRunner: Killing process!
15/05/17 05:03:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150516220719-0006/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/17 05:03:04 INFO Worker: Executor app-20150516220719-0006/1 finished with state KILLED exitStatus 1
15/05/17 05:03:04 INFO Worker: Cleaning up local directories for application app-20150516220719-0006
15/05/17 05:03:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A43069-22#-1667530123] was not delivered. [6] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/17 05:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40997
]
15/05/17 05:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40997
]
15/05/17 05:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40997]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40997
]
15/05/17 05:03:29 INFO Worker: Asked to launch executor app-20150517050329-0007/1 for PTITwitterStream
15/05/17 05:03:29 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=54862" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:54862/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150517050329-0007" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-17 14:10:39,494 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805353.tmp
2015-05-17 14:10:39,554 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805353.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805353
2015-05-17 14:10:39,644 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805354.tmp
2015-05-17 14:25:28,940 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805354.tmp
2015-05-17 14:25:28,981 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805354.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805354
2015-05-17 14:25:29,063 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805355.tmp
2015-05-17 14:35:05,889 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805355.tmp
2015-05-17 14:35:05,931 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805355.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805355
2015-05-17 14:35:06,027 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805356.tmp
2015-05-17 14:43:49,815 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805356.tmp
2015-05-17 14:43:49,851 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805356.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805356
2015-05-17 14:43:49,942 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805357.tmp
2015-05-17 14:48:37,356 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805357.tmp
2015-05-17 14:48:37,396 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805357.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805357
2015-05-17 14:48:37,473 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805358.tmp
2015-05-17 14:57:20,311 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805358.tmp
2015-05-17 14:57:20,354 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805358.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805358
2015-05-17 14:57:20,397 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805359.tmp
2015-05-17 15:10:22,653 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805359.tmp
2015-05-17 15:10:22,684 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805359.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805359
2015-05-17 15:10:22,817 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805360.tmp
2015-05-17 15:15:16,260 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805360.tmp
2015-05-17 15:15:16,311 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805360.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805360
2015-05-17 15:15:16,364 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805361.tmp
2015-05-17 15:22:45,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805361.tmp
2015-05-17 15:22:45,188 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805361.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805361
2015-05-17 15:22:45,276 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805362.tmp
2015-05-17 15:31:28,143 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805362.tmp
2015-05-17 15:31:28,196 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805362.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805362
2015-05-17 15:31:28,279 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805363.tmp
2015-05-17 15:38:36,963 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805363.tmp
2015-05-17 15:38:36,998 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805363.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805363
2015-05-17 15:38:37,074 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805364.tmp
2015-05-17 15:42:55,499 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805364.tmp
2015-05-17 15:42:55,541 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805364.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805364
2015-05-17 15:42:55,626 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805365.tmp
2015-05-17 15:47:44,745 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805365.tmp
2015-05-17 15:47:44,799 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805365.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805365
2015-05-17 15:47:44,890 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805366.tmp
2015-05-17 15:52:09,289 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805366.tmp
2015-05-17 15:52:09,330 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805366.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805366
2015-05-17 15:52:09,394 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805367.tmp
2015-05-17 15:55:51,778 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805367.tmp
2015-05-17 15:55:51,824 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805367.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805367
2015-05-17 15:55:51,878 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805368.tmp
2015-05-17 15:59:10,197 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805368.tmp
2015-05-17 15:59:10,233 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805368.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805368
2015-05-17 15:59:10,312 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805369.tmp
2015-05-17 16:01:34,471 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805369.tmp
2015-05-17 16:01:34,508 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805369.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805369
2015-05-17 16:01:34,548 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805370.tmp
2015-05-17 16:04:10,794 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805370.tmp
2015-05-17 16:04:10,833 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805370.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805370
2015-05-17 16:04:10,878 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805371.tmp
2015-05-17 16:10:41,465 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805371.tmp
2015-05-17 16:10:41,498 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805371.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805371
2015-05-17 16:10:41,541 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805372.tmp
2015-05-17 16:21:30,638 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805372.tmp
2015-05-17 16:21:30,693 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805372.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805372
2015-05-17 16:21:30,755 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805373.tmp
2015-05-17 16:30:08,624 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805373.tmp
2015-05-17 16:30:08,657 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805373.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805373
2015-05-17 16:30:08,735 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805374.tmp
2015-05-17 16:38:20,596 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805374.tmp
2015-05-17 16:38:20,645 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805374.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805374
2015-05-17 16:38:20,729 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805375.tmp
2015-05-17 16:44:39,378 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805375.tmp
2015-05-17 16:44:39,436 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805375.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805375
2015-05-17 16:44:39,529 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805376.tmp
2015-05-17 16:51:04,138 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805376.tmp
2015-05-17 16:51:04,164 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805376.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805376
2015-05-17 16:51:04,240 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805377.tmp
2015-05-17 17:06:29,666 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805377.tmp
2015-05-17 17:06:29,716 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805377.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805377
2015-05-17 17:06:29,786 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805378.tmp
2015-05-17 17:17:24,819 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805378.tmp
2015-05-17 17:17:24,859 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805378.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805378
2015-05-17 17:17:24,948 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805379.tmp
2015-05-17 17:30:08,124 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805379.tmp
2015-05-17 17:30:08,151 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805379.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805379
2015-05-17 17:30:08,258 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805380.tmp
2015-05-17 17:44:09,360 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805380.tmp
2015-05-17 17:44:09,395 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805380.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805380
2015-05-17 17:44:09,471 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805381.tmp
2015-05-17 17:51:22,219 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805381.tmp
2015-05-17 17:51:22,268 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805381.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805381
2015-05-17 17:51:22,359 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805382.tmp
2015-05-17 17:57:47,999 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805382.tmp
2015-05-17 17:57:48,042 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805382.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805382
2015-05-17 17:57:48,089 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805383.tmp
2015-05-17 18:07:13,049 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805383.tmp
2015-05-17 18:07:13,084 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805383.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805383
2015-05-17 18:07:13,146 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805384.tmp
2015-05-17 18:16:32,030 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805384.tmp
2015-05-17 18:16:32,084 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805384.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805384
2015-05-17 18:16:32,171 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805385.tmp
2015-05-17 18:24:25,823 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805385.tmp
2015-05-17 18:24:25,863 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805385.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805385
2015-05-17 18:24:25,911 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805386.tmp
2015-05-17 18:30:14,584 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805386.tmp
2015-05-17 18:30:14,623 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805386.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805386
2015-05-17 18:30:14,714 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805387.tmp
2015-05-17 18:34:48,135 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805387.tmp
2015-05-17 18:34:48,187 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805387.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805387
2015-05-17 18:34:48,276 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805388.tmp
2015-05-17 18:37:12,447 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805388.tmp
2015-05-17 18:37:12,476 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805388.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805388
2015-05-17 18:37:12,574 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805389.tmp
2015-05-17 18:39:24,715 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805389.tmp
2015-05-17 18:39:24,757 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805389.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805389
2015-05-17 18:39:24,804 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805390.tmp
2015-05-17 18:44:37,309 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805390.tmp
2015-05-17 18:44:37,356 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805390.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805390
2015-05-17 18:44:37,440 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805391.tmp
2015-05-17 18:49:19,900 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805391.tmp
2015-05-17 18:49:19,944 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805391.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805391
2015-05-17 18:49:19,983 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805392.tmp
2015-05-17 18:54:32,533 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805392.tmp
2015-05-17 18:54:32,580 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805392.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805392
2015-05-17 18:54:32,667 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805393.tmp
2015-05-17 19:02:34,402 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805393.tmp
2015-05-17 19:02:34,452 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805393.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805393
2015-05-17 19:02:34,535 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805394.tmp
2015-05-17 19:14:31,654 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805394.tmp
2015-05-17 19:14:31,701 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805394.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805394
2015-05-17 19:14:31,789 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805395.tmp
2015-05-17 19:28:46,036 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805395.tmp
2015-05-17 19:28:46,077 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805395.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805395
2015-05-17 19:28:46,145 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805396.tmp
2015-05-17 19:38:25,075 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805396.tmp
2015-05-17 19:38:25,130 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805396.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805396
2015-05-17 19:38:25,233 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805397.tmp
2015-05-17 19:55:56,776 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805397.tmp
2015-05-17 19:55:56,819 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805397.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805397
2015-05-17 19:55:56,896 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805398.tmp
2015-05-17 20:08:40,010 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805398.tmp
2015-05-17 20:08:40,059 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805398.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805398
2015-05-17 20:08:40,132 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805399.tmp
15/05/17 11:24:04 INFO Worker: Asked to kill executor app-20150517050329-0007/1
15/05/17 11:24:04 INFO ExecutorRunner: Runner thread for executor app-20150517050329-0007/1 interrupted
15/05/17 11:24:04 INFO ExecutorRunner: Killing process!
15/05/17 11:24:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150517050329-0007/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/17 11:24:04 INFO Worker: Executor app-20150517050329-0007/1 finished with state KILLED exitStatus 1
15/05/17 11:24:04 INFO Worker: Cleaning up local directories for application app-20150517050329-0007
15/05/17 11:24:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A44855-26#1261500436] was not delivered. [7] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/17 11:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59851
]
15/05/17 11:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59851
]
15/05/17 11:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59851]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59851
]
15/05/17 11:24:37 INFO Worker: Asked to launch executor app-20150517112437-0008/1 for PTITwitterStream
15/05/17 11:24:37 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=50957" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:50957/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150517112437-0008" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-17 20:50:13,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805399.tmp
2015-05-17 20:50:13,163 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805399.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805399
2015-05-17 20:50:13,209 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805400.tmp
2015-05-17 21:04:50,489 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805400.tmp
2015-05-17 21:04:50,528 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805400.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805400
2015-05-17 21:04:50,616 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805401.tmp
2015-05-17 21:21:16,008 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805401.tmp
2015-05-17 21:21:16,043 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805401.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805401
2015-05-17 21:21:16,143 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805402.tmp
2015-05-17 21:28:16,821 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805402.tmp
2015-05-17 21:28:16,856 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805402.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805402
2015-05-17 21:28:16,902 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805403.tmp
2015-05-17 21:35:23,626 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805403.tmp
2015-05-17 21:35:23,662 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805403.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805403
2015-05-17 21:35:23,721 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805404.tmp
2015-05-17 21:41:54,345 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805404.tmp
2015-05-17 21:41:54,370 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805404.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805404
2015-05-17 21:41:54,415 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805405.tmp
2015-05-17 21:47:37,968 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805405.tmp
2015-05-17 21:47:38,019 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805405.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805405
2015-05-17 21:47:38,118 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805406.tmp
2015-05-17 21:56:44,866 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805406.tmp
2015-05-17 21:56:44,909 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805406.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805406
2015-05-17 21:56:45,001 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805407.tmp
2015-05-17 22:00:23,375 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805407.tmp
2015-05-17 22:00:23,412 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805407.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805407
2015-05-17 22:00:23,501 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805408.tmp
2015-05-17 22:02:41,653 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805408.tmp
2015-05-17 22:02:41,796 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805408.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805408
2015-05-17 22:02:42,226 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805409.tmp
2015-05-17 22:05:19,030 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805409.tmp
2015-05-17 22:05:19,066 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805409.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805409
2015-05-17 22:05:19,109 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805410.tmp
2015-05-17 22:07:49,358 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805410.tmp
2015-05-17 22:07:49,398 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805410.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805410
2015-05-17 22:07:49,494 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805411.tmp
2015-05-17 22:11:36,820 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805411.tmp
2015-05-17 22:11:36,896 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805411.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805411
2015-05-17 22:11:36,955 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805412.tmp
2015-05-17 22:14:49,205 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805412.tmp
2015-05-17 22:14:49,232 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805412.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805412
2015-05-17 22:14:49,308 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805413.tmp
2015-05-17 22:17:20,545 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805413.tmp
2015-05-17 22:17:20,593 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805413.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805413
2015-05-17 22:17:20,692 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805414.tmp
2015-05-17 22:20:07,913 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805414.tmp
2015-05-17 22:20:07,958 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805414.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805414
2015-05-17 22:20:08,054 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805415.tmp
2015-05-17 22:23:44,369 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805415.tmp
2015-05-17 22:23:44,409 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805415.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805415
2015-05-17 22:23:44,489 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805416.tmp
2015-05-17 22:33:34,407 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805416.tmp
2015-05-17 22:33:34,458 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805416.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805416
2015-05-17 22:33:34,537 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805417.tmp
2015-05-17 22:39:13,140 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805417.tmp
2015-05-17 22:39:13,186 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805417.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805417
2015-05-17 22:39:13,262 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805418.tmp
2015-05-17 22:43:56,755 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805418.tmp
2015-05-17 22:43:56,793 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805418.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805418
2015-05-17 22:43:56,852 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805419.tmp
2015-05-17 22:50:14,459 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805419.tmp
2015-05-17 22:50:14,509 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805419.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805419
2015-05-17 22:50:14,592 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805420.tmp
2015-05-17 22:53:26,892 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805420.tmp
2015-05-17 22:53:26,945 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805420.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805420
2015-05-17 22:53:27,025 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805421.tmp
2015-05-17 22:57:22,369 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805421.tmp
2015-05-17 22:57:22,414 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805421.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805421
2015-05-17 22:57:22,486 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805422.tmp
2015-05-17 23:05:04,232 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805422.tmp
2015-05-17 23:05:04,265 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805422.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805422
2015-05-17 23:05:04,316 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805423.tmp
2015-05-17 23:12:59,102 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805423.tmp
2015-05-17 23:12:59,139 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805423.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805423
2015-05-17 23:12:59,175 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805424.tmp
2015-05-17 23:21:03,030 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805424.tmp
2015-05-17 23:21:03,068 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805424.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805424
2015-05-17 23:21:03,141 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805425.tmp
2015-05-17 23:31:04,062 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805425.tmp
2015-05-17 23:31:04,094 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805425.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805425
2015-05-17 23:31:04,185 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805426.tmp
2015-05-17 23:41:11,204 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805426.tmp
2015-05-17 23:41:11,244 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805426.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805426
2015-05-17 23:41:11,328 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805427.tmp
2015-05-17 23:54:55,593 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805427.tmp
2015-05-17 23:54:55,625 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805427.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805427
2015-05-17 23:54:55,679 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805428.tmp
15/05/17 15:00:03 INFO Worker: Asked to kill executor app-20150517112437-0008/1
15/05/17 15:00:03 INFO ExecutorRunner: Runner thread for executor app-20150517112437-0008/1 interrupted
15/05/17 15:00:03 INFO ExecutorRunner: Killing process!
15/05/17 15:00:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150517112437-0008/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/17 15:00:03 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A47217-30#-277764310] was not delivered. [8] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/17 15:00:03 INFO Worker: Executor app-20150517112437-0008/1 finished with state KILLED exitStatus 1
15/05/17 15:00:03 INFO Worker: Cleaning up local directories for application app-20150517112437-0008
15/05/17 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33824
]
15/05/17 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33824
]
15/05/17 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33824]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33824
]
2015-05-18 00:00:13,082 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-18 00:00:13,164 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213083.tmp
15/05/17 15:00:15 INFO Worker: Asked to launch executor app-20150517150015-0009/1 for PTITwitterStream
15/05/17 15:00:15 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=52258" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:52258/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150517150015-0009" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-18 00:50:31,587 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213083.tmp
2015-05-18 00:50:31,629 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213083.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213083
2015-05-18 00:50:31,719 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213084.tmp
2015-05-18 00:59:58,065 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805428.tmp at 1431892798065
2015-05-18 00:59:58,070 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805428.tmp
2015-05-18 00:59:58,106 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805428.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150517/user_tweets.1431802805428
2015-05-18 00:59:58,116 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-18 01:32:58,778 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213084.tmp
2015-05-18 01:32:58,830 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213084.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213084
2015-05-18 01:32:58,903 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213085.tmp
2015-05-18 02:31:56,748 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213085.tmp
2015-05-18 02:31:56,786 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213085.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213085
2015-05-18 02:31:56,869 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213086.tmp
2015-05-18 04:24:03,740 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213086.tmp
2015-05-18 04:24:03,778 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213086.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213086
2015-05-18 04:24:03,859 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213087.tmp
2015-05-18 08:23:29,534 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213087.tmp
2015-05-18 08:23:29,597 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213087.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213087
2015-05-18 08:23:29,664 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213088.tmp
15/05/17 23:24:03 INFO Worker: Asked to kill executor app-20150517150015-0009/1
15/05/17 23:24:03 INFO ExecutorRunner: Runner thread for executor app-20150517150015-0009/1 interrupted
15/05/17 23:24:03 INFO ExecutorRunner: Killing process!
15/05/17 23:24:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150517150015-0009/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/17 23:24:04 INFO Worker: Executor app-20150517150015-0009/1 finished with state KILLED exitStatus 1
15/05/17 23:24:04 INFO Worker: Cleaning up local directories for application app-20150517150015-0009
15/05/17 23:24:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A37000-34#-294740734] was not delivered. [9] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/17 23:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53284
]
15/05/17 23:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53284
]
15/05/17 23:24:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53284]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53284
]
15/05/17 23:24:48 INFO Worker: Asked to launch executor app-20150517232448-0010/1 for PTITwitterStream
15/05/17 23:24:48 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=55724" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:55724/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150517232448-0010" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-18 09:10:56,523 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213088.tmp
2015-05-18 09:10:56,563 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213088.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213088
2015-05-18 09:10:56,631 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213089.tmp
2015-05-18 09:34:49,806 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213089.tmp
2015-05-18 09:34:49,848 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213089.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213089
2015-05-18 09:34:49,941 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213090.tmp
2015-05-18 10:16:51,298 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213090.tmp
2015-05-18 10:16:51,331 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213090.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213090
2015-05-18 10:16:51,378 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213091.tmp
2015-05-18 11:11:00,460 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213091.tmp
2015-05-18 11:11:00,488 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213091.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213091
2015-05-18 11:11:00,538 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213092.tmp
2015-05-18 11:29:38,163 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213092.tmp
2015-05-18 11:29:38,213 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213092.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213092
2015-05-18 11:29:38,263 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213093.tmp
2015-05-18 11:43:45,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213093.tmp
2015-05-18 11:43:45,617 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213093.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213093
2015-05-18 11:43:45,739 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213094.tmp
2015-05-18 11:55:04,701 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213094.tmp
2015-05-18 11:55:04,737 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213094.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213094
2015-05-18 11:55:04,785 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213095.tmp
2015-05-18 12:09:25,127 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213095.tmp
2015-05-18 12:09:25,156 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213095.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213095
2015-05-18 12:09:25,199 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213096.tmp
2015-05-18 12:22:13,356 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213096.tmp
2015-05-18 12:22:13,399 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213096.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213096
2015-05-18 12:22:13,448 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213097.tmp
2015-05-18 12:33:02,429 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213097.tmp
2015-05-18 12:33:02,466 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213097.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213097
2015-05-18 12:33:02,510 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213098.tmp
2015-05-18 13:01:11,756 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213098.tmp
2015-05-18 13:01:11,802 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213098.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213098
2015-05-18 13:01:11,884 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213099.tmp
2015-05-18 13:28:26,011 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213099.tmp
2015-05-18 13:28:26,042 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213099.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213099
2015-05-18 13:28:26,112 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213100.tmp
2015-05-18 13:45:54,641 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213100.tmp
2015-05-18 13:45:54,675 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213100.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213100
2015-05-18 13:45:54,731 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213101.tmp
2015-05-18 14:17:29,148 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213101.tmp
2015-05-18 14:17:29,183 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213101.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213101
2015-05-18 14:17:29,275 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213102.tmp
2015-05-18 15:04:05,391 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213102.tmp
2015-05-18 15:04:05,444 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213102.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213102
2015-05-18 15:04:05,520 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213103.tmp
2015-05-18 15:16:31,606 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213103.tmp
2015-05-18 15:16:31,642 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213103.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213103
2015-05-18 15:16:31,733 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213104.tmp
2015-05-18 15:37:01,459 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213104.tmp
2015-05-18 15:37:01,489 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213104.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213104
2015-05-18 15:37:01,577 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213105.tmp
15/05/18 06:56:04 INFO Worker: Asked to kill executor app-20150517232448-0010/1
15/05/18 06:56:04 INFO ExecutorRunner: Runner thread for executor app-20150517232448-0010/1 interrupted
15/05/18 06:56:04 INFO ExecutorRunner: Killing process!
15/05/18 06:56:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150517232448-0010/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/18 06:56:04 INFO Worker: Executor app-20150517232448-0010/1 finished with state KILLED exitStatus 1
15/05/18 06:56:04 INFO Worker: Cleaning up local directories for application app-20150517232448-0010
15/05/18 06:56:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A40228-38#1473667472] was not delivered. [10] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/18 06:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49739
]
15/05/18 06:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49739
]
15/05/18 06:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49739]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49739
]
15/05/18 06:56:50 INFO Worker: Asked to launch executor app-20150518065650-0011/1 for PTITwitterStream
15/05/18 06:56:50 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=56590" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:56590/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150518065650-0011" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-18 16:11:29,054 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213105.tmp
2015-05-18 16:11:29,109 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213105.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213105
2015-05-18 16:11:29,197 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213106.tmp
2015-05-18 16:33:19,978 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213106.tmp
2015-05-18 16:33:20,022 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213106.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213106
2015-05-18 16:33:20,095 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213107.tmp
2015-05-18 17:21:16,533 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213107.tmp
2015-05-18 17:21:16,579 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213107.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213107
2015-05-18 17:21:16,661 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213108.tmp
2015-05-18 17:59:49,760 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213108.tmp
2015-05-18 17:59:49,805 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213108.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213108
2015-05-18 17:59:49,853 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213109.tmp
2015-05-18 18:11:45,876 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213109.tmp
2015-05-18 18:11:45,933 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213109.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213109
2015-05-18 18:11:46,020 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213110.tmp
2015-05-18 18:20:15,899 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213110.tmp
2015-05-18 18:20:15,937 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213110.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213110
2015-05-18 18:20:15,983 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213111.tmp
2015-05-18 18:25:34,533 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213111.tmp
2015-05-18 18:25:34,576 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213111.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213111
2015-05-18 18:25:34,628 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213112.tmp
2015-05-18 18:31:35,258 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213112.tmp
2015-05-18 18:31:35,320 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213112.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213112
2015-05-18 18:31:35,381 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213113.tmp
2015-05-18 18:38:06,009 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213113.tmp
2015-05-18 18:38:06,057 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213113.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213113
2015-05-18 18:38:06,101 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213114.tmp
2015-05-18 18:42:36,550 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213114.tmp
2015-05-18 18:42:36,597 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213114.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213114
2015-05-18 18:42:36,661 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213115.tmp
2015-05-18 18:49:32,335 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213115.tmp
2015-05-18 18:49:32,373 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213115.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213115
2015-05-18 18:49:32,447 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213116.tmp
2015-05-18 18:55:56,073 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213116.tmp
2015-05-18 18:55:56,105 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213116.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213116
2015-05-18 18:55:56,146 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213117.tmp
2015-05-18 18:59:02,458 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213117.tmp
2015-05-18 18:59:02,495 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213117.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213117
2015-05-18 18:59:02,597 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213118.tmp
2015-05-18 19:03:15,033 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213118.tmp
2015-05-18 19:03:15,061 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213118.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213118
2015-05-18 19:03:15,158 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213119.tmp
2015-05-18 19:08:04,620 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213119.tmp
2015-05-18 19:08:04,658 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213119.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213119
2015-05-18 19:08:04,751 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213120.tmp
2015-05-18 19:15:28,402 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213120.tmp
2015-05-18 19:15:28,426 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213120.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213120
2015-05-18 19:15:28,474 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213121.tmp
2015-05-18 19:25:17,462 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213121.tmp
2015-05-18 19:25:17,484 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213121.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213121
2015-05-18 19:25:17,529 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213122.tmp
2015-05-18 19:52:08,832 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213122.tmp
2015-05-18 19:52:08,874 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213122.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213122
2015-05-18 19:52:08,994 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213123.tmp
2015-05-18 20:13:34,900 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213123.tmp
2015-05-18 20:13:34,940 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213123.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213123
2015-05-18 20:13:35,001 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213124.tmp
2015-05-18 20:31:17,703 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213124.tmp
2015-05-18 20:31:17,746 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213124.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213124
2015-05-18 20:31:17,815 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213125.tmp
2015-05-18 20:41:49,775 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213125.tmp
2015-05-18 20:41:49,819 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213125.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213125
2015-05-18 20:41:49,888 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213126.tmp
2015-05-18 20:54:38,149 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213126.tmp
2015-05-18 20:54:38,198 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213126.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213126
2015-05-18 20:54:38,248 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213127.tmp
2015-05-18 21:04:45,277 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213127.tmp
2015-05-18 21:04:45,317 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213127.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213127
2015-05-18 21:04:45,396 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213128.tmp
2015-05-18 21:17:59,701 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213128.tmp
2015-05-18 21:17:59,757 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213128.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213128
2015-05-18 21:17:59,857 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213129.tmp
2015-05-18 21:34:13,283 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213129.tmp
2015-05-18 21:34:13,311 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213129.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213129
2015-05-18 21:34:13,350 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213130.tmp
2015-05-18 21:43:59,328 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213130.tmp
2015-05-18 21:43:59,370 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213130.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213130
2015-05-18 21:43:59,465 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213131.tmp
2015-05-18 21:51:12,107 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213131.tmp
2015-05-18 21:51:12,156 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213131.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213131
2015-05-18 21:51:12,254 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213132.tmp
2015-05-18 21:55:05,593 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213132.tmp
2015-05-18 21:55:05,640 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213132.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213132
2015-05-18 21:55:05,738 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213133.tmp
2015-05-18 21:59:18,070 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213133.tmp
2015-05-18 21:59:18,107 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213133.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213133
2015-05-18 21:59:18,191 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213134.tmp
2015-05-18 22:04:12,666 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213134.tmp
2015-05-18 22:04:12,707 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213134.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213134
2015-05-18 22:04:12,755 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213135.tmp
2015-05-18 22:10:01,322 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213135.tmp
2015-05-18 22:10:01,359 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213135.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213135
2015-05-18 22:10:01,446 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213136.tmp
2015-05-18 22:14:37,872 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213136.tmp
2015-05-18 22:14:37,911 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213136.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213136
2015-05-18 22:14:38,008 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213137.tmp
2015-05-18 22:19:48,495 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213137.tmp
2015-05-18 22:19:48,524 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213137.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213137
2015-05-18 22:19:48,573 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213138.tmp
2015-05-18 22:25:12,160 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213138.tmp
2015-05-18 22:25:12,201 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213138.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213138
2015-05-18 22:25:12,278 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213139.tmp
2015-05-18 22:29:42,750 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213139.tmp
2015-05-18 22:29:42,803 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213139.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213139
2015-05-18 22:29:42,883 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213140.tmp
2015-05-18 22:33:37,255 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213140.tmp
2015-05-18 22:33:37,306 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213140.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213140
2015-05-18 22:33:37,364 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213141.tmp
2015-05-18 22:39:37,951 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213141.tmp
2015-05-18 22:39:37,993 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213141.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213141
2015-05-18 22:39:38,073 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213142.tmp
2015-05-18 22:45:26,646 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213142.tmp
2015-05-18 22:45:26,688 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213142.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213142
2015-05-18 22:45:26,759 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213143.tmp
2015-05-18 22:51:34,359 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213143.tmp
2015-05-18 22:51:34,409 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213143.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213143
2015-05-18 22:51:34,496 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213144.tmp
2015-05-18 22:54:21,718 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213144.tmp
2015-05-18 22:54:21,750 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213144.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213144
2015-05-18 22:54:21,853 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213145.tmp
2015-05-18 22:57:52,137 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213145.tmp
2015-05-18 22:57:52,172 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213145.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213145
2015-05-18 22:57:52,257 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213146.tmp
2015-05-18 22:59:28,337 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213146.tmp
2015-05-18 22:59:28,382 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213146.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213146
2015-05-18 22:59:28,477 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213147.tmp
2015-05-18 23:02:47,739 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213147.tmp
2015-05-18 23:02:47,780 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213147.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213147
2015-05-18 23:02:47,863 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213148.tmp
15/05/18 14:03:04 INFO Worker: Asked to kill executor app-20150518065650-0011/1
15/05/18 14:03:04 INFO ExecutorRunner: Runner thread for executor app-20150518065650-0011/1 interrupted
15/05/18 14:03:04 INFO ExecutorRunner: Killing process!
15/05/18 14:03:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150518065650-0011/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/18 14:03:04 INFO Worker: Executor app-20150518065650-0011/1 finished with state KILLED exitStatus 1
15/05/18 14:03:04 INFO Worker: Cleaning up local directories for application app-20150518065650-0011
15/05/18 14:03:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A42610-42#1948848006] was not delivered. [11] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/18 14:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49383
]
15/05/18 14:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49383
]
15/05/18 14:03:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49383]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49383
]
15/05/18 14:03:58 INFO Worker: Asked to launch executor app-20150518140358-0012/1 for PTITwitterStream
15/05/18 14:03:58 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=34638" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:34638/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150518140358-0012" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-18 23:05:59,134 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213148.tmp
2015-05-18 23:05:59,183 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213148.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213148
2015-05-18 23:05:59,230 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213149.tmp
2015-05-18 23:07:54,411 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213149.tmp
2015-05-18 23:07:54,449 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213149.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213149
2015-05-18 23:07:54,547 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213150.tmp
2015-05-18 23:10:08,714 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213150.tmp
2015-05-18 23:10:08,764 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213150.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213150
2015-05-18 23:10:08,851 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213151.tmp
2015-05-18 23:12:58,069 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213151.tmp
2015-05-18 23:12:58,112 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213151.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213151
2015-05-18 23:12:58,184 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213152.tmp
2015-05-18 23:17:39,622 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213152.tmp
2015-05-18 23:17:39,663 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213152.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213152
2015-05-18 23:17:39,744 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213153.tmp
2015-05-18 23:23:23,269 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213153.tmp
2015-05-18 23:23:23,307 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213153.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213153
2015-05-18 23:23:23,363 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213154.tmp
2015-05-18 23:29:47,979 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213154.tmp
2015-05-18 23:29:48,017 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213154.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213154
2015-05-18 23:29:48,097 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213155.tmp
2015-05-18 23:36:12,756 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213155.tmp
2015-05-18 23:36:12,785 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213155.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213155
2015-05-18 23:36:12,830 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213156.tmp
2015-05-18 23:46:18,801 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213156.tmp
2015-05-18 23:46:18,850 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213156.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213156
2015-05-18 23:46:18,947 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213157.tmp
2015-05-18 23:56:41,900 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213157.tmp
2015-05-18 23:56:41,941 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213157.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213157
2015-05-18 23:56:42,035 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213158.tmp
2015-05-19 00:00:05,255 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-19 00:00:05,323 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605256.tmp
15/05/18 15:00:09 INFO Worker: Asked to kill executor app-20150518140358-0012/1
15/05/18 15:00:09 INFO ExecutorRunner: Runner thread for executor app-20150518140358-0012/1 interrupted
15/05/18 15:00:09 INFO ExecutorRunner: Killing process!
15/05/18 15:00:09 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150518140358-0012/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/18 15:00:09 INFO Worker: Executor app-20150518140358-0012/1 finished with state KILLED exitStatus 1
15/05/18 15:00:09 INFO Worker: Cleaning up local directories for application app-20150518140358-0012
15/05/18 15:00:09 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A47506-46#1783180485] was not delivered. [12] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/18 15:00:09 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33526
]
15/05/18 15:00:09 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33526
]
15/05/18 15:00:09 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33526]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33526
]
15/05/18 15:00:19 INFO Worker: Asked to launch executor app-20150518150019-0013/1 for PTITwitterStream
15/05/18 15:00:20 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=59413" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:59413/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150518150019-0013" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-19 00:08:30,209 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605256.tmp
2015-05-19 00:08:30,266 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605256.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605256
2015-05-19 00:08:30,344 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605257.tmp
2015-05-19 00:22:01,577 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605257.tmp
2015-05-19 00:22:01,618 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605257.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605257
2015-05-19 00:22:01,745 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605258.tmp
2015-05-19 00:30:57,572 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605258.tmp
2015-05-19 00:30:57,612 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605258.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605258
2015-05-19 00:30:57,716 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605259.tmp
2015-05-19 00:36:27,264 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605259.tmp
2015-05-19 00:36:27,300 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605259.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605259
2015-05-19 00:36:27,349 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605260.tmp
2015-05-19 00:41:27,829 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605260.tmp
2015-05-19 00:41:27,874 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605260.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605260
2015-05-19 00:41:27,960 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605261.tmp
2015-05-19 00:46:58,455 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605261.tmp
2015-05-19 00:46:58,500 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605261.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605261
2015-05-19 00:46:58,581 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605262.tmp
2015-05-19 00:51:34,992 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605262.tmp
2015-05-19 00:51:35,041 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605262.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605262
2015-05-19 00:51:35,135 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605263.tmp
2015-05-19 00:58:47,806 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605263.tmp
2015-05-19 00:58:47,860 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605263.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605263
2015-05-19 00:58:47,949 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605264.tmp
2015-05-19 01:00:02,259 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213158.tmp at 1431979202259
2015-05-19 01:00:02,265 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213158.tmp
2015-05-19 01:00:02,301 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213158.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150518/user_tweets.1431889213158
2015-05-19 01:00:02,308 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-19 01:10:06,955 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605264.tmp
2015-05-19 01:10:06,990 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605264.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605264
2015-05-19 01:10:07,076 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605265.tmp
2015-05-19 01:26:27,441 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605265.tmp
2015-05-19 01:26:27,483 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605265.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605265
2015-05-19 01:26:27,567 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605266.tmp
2015-05-19 01:54:29,742 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605266.tmp
2015-05-19 01:54:29,783 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605266.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605266
2015-05-19 01:54:29,865 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605267.tmp
2015-05-19 02:25:13,106 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605267.tmp
2015-05-19 02:25:13,150 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605267.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605267
2015-05-19 02:25:13,207 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605268.tmp
2015-05-19 04:20:50,357 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605268.tmp
2015-05-19 04:20:50,413 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605268.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605268
2015-05-19 04:20:50,497 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605269.tmp
2015-05-19 06:56:49,979 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605269.tmp
2015-05-19 06:56:50,025 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605269.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605269
2015-05-19 06:56:50,108 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605270.tmp
15/05/18 22:35:04 INFO Worker: Asked to kill executor app-20150518150019-0013/1
15/05/18 22:35:04 INFO ExecutorRunner: Runner thread for executor app-20150518150019-0013/1 interrupted
15/05/18 22:35:04 INFO ExecutorRunner: Killing process!
15/05/18 22:35:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150518150019-0013/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/18 22:35:04 INFO Worker: Executor app-20150518150019-0013/1 finished with state KILLED exitStatus 1
15/05/18 22:35:04 INFO Worker: Cleaning up local directories for application app-20150518150019-0013
15/05/18 22:35:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A52803-50#-308342156] was not delivered. [13] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/18 22:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40492
]
15/05/18 22:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40492
]
15/05/18 22:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:40492]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:40492
]
15/05/18 22:36:07 INFO Worker: Asked to launch executor app-20150518223607-0014/1 for PTITwitterStream
15/05/18 22:36:07 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=36150" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:36150/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150518223607-0014" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-19 09:40:15,439 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605270.tmp
2015-05-19 09:40:15,466 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605270.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605270
2015-05-19 09:40:15,517 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605271.tmp
2015-05-19 10:33:30,159 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605271.tmp
2015-05-19 10:33:30,206 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605271.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605271
2015-05-19 10:33:30,286 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605272.tmp
2015-05-19 10:52:19,748 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605272.tmp
2015-05-19 10:52:19,781 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605272.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605272
2015-05-19 10:52:19,858 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605273.tmp
2015-05-19 11:06:29,964 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605273.tmp
2015-05-19 11:06:29,998 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605273.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605273
2015-05-19 11:06:30,080 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605274.tmp
2015-05-19 11:16:07,017 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605274.tmp
2015-05-19 11:16:07,061 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605274.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605274
2015-05-19 11:16:07,137 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605275.tmp
2015-05-19 11:25:31,992 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605275.tmp
2015-05-19 11:25:32,036 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605275.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605275
2015-05-19 11:25:32,113 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605276.tmp
2015-05-19 11:34:26,925 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605276.tmp
2015-05-19 11:34:26,975 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605276.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605276
2015-05-19 11:34:27,056 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605277.tmp
2015-05-19 11:46:22,060 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605277.tmp
2015-05-19 11:46:22,087 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605277.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605277
2015-05-19 11:46:22,131 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605278.tmp
2015-05-19 12:01:18,386 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605278.tmp
2015-05-19 12:01:18,434 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605278.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605278
2015-05-19 12:01:18,513 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605279.tmp
2015-05-19 12:17:52,027 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605279.tmp
2015-05-19 12:17:52,063 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605279.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605279
2015-05-19 12:17:52,106 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605280.tmp
2015-05-19 12:22:22,540 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605280.tmp
2015-05-19 12:22:22,569 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605280.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605280
2015-05-19 12:22:22,650 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605281.tmp
2015-05-19 12:28:33,033 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605281.tmp
2015-05-19 12:28:33,114 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605281.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605281
2015-05-19 12:28:33,195 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605282.tmp
2015-05-19 12:47:03,512 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605282.tmp
2015-05-19 12:47:03,548 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605282.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605282
2015-05-19 12:47:03,599 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605283.tmp
2015-05-19 12:58:28,646 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605283.tmp
2015-05-19 12:58:28,673 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605283.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605283
2015-05-19 12:58:28,729 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605284.tmp
2015-05-19 13:10:40,858 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605284.tmp
2015-05-19 13:10:40,894 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605284.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605284
2015-05-19 13:10:40,956 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605285.tmp
2015-05-19 13:31:03,743 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605285.tmp
2015-05-19 13:31:03,774 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605285.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605285
2015-05-19 13:31:03,865 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605286.tmp
2015-05-19 14:02:15,375 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605286.tmp
2015-05-19 14:02:15,416 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605286.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605286
2015-05-19 14:02:15,494 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605287.tmp
2015-05-19 14:38:06,290 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605287.tmp
2015-05-19 14:38:06,321 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605287.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605287
2015-05-19 14:38:06,357 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605288.tmp
15/05/19 05:54:04 INFO Worker: Asked to kill executor app-20150518223607-0014/1
15/05/19 05:54:04 INFO ExecutorRunner: Runner thread for executor app-20150518223607-0014/1 interrupted
15/05/19 05:54:04 INFO ExecutorRunner: Killing process!
15/05/19 05:54:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150518223607-0014/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/19 05:54:04 INFO Worker: Executor app-20150518223607-0014/1 finished with state KILLED exitStatus 1
15/05/19 05:54:04 INFO Worker: Cleaning up local directories for application app-20150518223607-0014
15/05/19 05:54:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A54509-54#1290118568] was not delivered. [14] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/19 05:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:34933
]
15/05/19 05:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:34933
]
15/05/19 05:54:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:34933]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:34933
]
15/05/19 05:54:17 INFO Worker: Asked to launch executor app-20150519055417-0015/1 for PTITwitterStream
15/05/19 05:54:17 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=40866" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:40866/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150519055417-0015" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-19 14:55:08,848 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605288.tmp
2015-05-19 14:55:08,892 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605288.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605288
2015-05-19 14:55:08,945 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605289.tmp
2015-05-19 15:12:51,512 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605289.tmp
2015-05-19 15:12:51,556 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605289.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605289
2015-05-19 15:12:51,619 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605290.tmp
2015-05-19 15:27:53,903 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605290.tmp
2015-05-19 15:27:53,954 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605290.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605290
2015-05-19 15:27:54,024 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605291.tmp
2015-05-19 15:39:48,039 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605291.tmp
2015-05-19 15:39:48,096 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605291.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605291
2015-05-19 15:39:48,185 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605292.tmp
2015-05-19 15:51:07,137 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605292.tmp
2015-05-19 15:51:07,171 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605292.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605292
2015-05-19 15:51:07,253 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605293.tmp
2015-05-19 15:57:25,847 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605293.tmp
2015-05-19 15:57:25,890 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605293.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605293
2015-05-19 15:57:25,963 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605294.tmp
2015-05-19 16:09:02,997 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605294.tmp
2015-05-19 16:09:03,023 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605294.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605294
2015-05-19 16:09:03,056 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605295.tmp
2015-05-19 16:22:16,335 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605295.tmp
2015-05-19 16:22:16,366 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605295.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605295
2015-05-19 16:22:16,412 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605296.tmp
2015-05-19 16:37:11,748 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605296.tmp
2015-05-19 16:37:11,798 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605296.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605296
2015-05-19 16:37:11,873 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605297.tmp
2015-05-19 17:08:38,193 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605297.tmp
2015-05-19 17:08:38,220 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605297.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605297
2015-05-19 17:08:38,301 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605298.tmp
2015-05-19 17:26:33,773 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605298.tmp
2015-05-19 17:26:33,804 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605298.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605298
2015-05-19 17:26:33,874 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605299.tmp
2015-05-19 17:41:59,327 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605299.tmp
2015-05-19 17:41:59,368 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605299.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605299
2015-05-19 17:41:59,435 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605300.tmp
2015-05-19 18:05:20,359 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605300.tmp
2015-05-19 18:05:20,396 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605300.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605300
2015-05-19 18:05:20,455 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605301.tmp
2015-05-19 18:30:45,597 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605301.tmp
2015-05-19 18:30:45,640 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605301.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605301
2015-05-19 18:30:45,715 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605302.tmp
2015-05-19 18:57:42,977 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605302.tmp
2015-05-19 18:57:43,006 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605302.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605302
2015-05-19 18:57:43,043 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605303.tmp
2015-05-19 19:17:14,020 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605303.tmp
2015-05-19 19:17:14,053 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605303.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605303
2015-05-19 19:17:14,115 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605304.tmp
2015-05-19 19:46:07,578 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605304.tmp
2015-05-19 19:46:07,601 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605304.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605304
2015-05-19 19:46:07,637 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605305.tmp
2015-05-19 20:10:33,916 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605305.tmp
2015-05-19 20:10:33,959 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605305.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605305
2015-05-19 20:10:34,035 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605306.tmp
2015-05-19 20:22:11,217 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605306.tmp
2015-05-19 20:22:11,246 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605306.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605306
2015-05-19 20:22:11,285 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605307.tmp
2015-05-19 20:32:43,386 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605307.tmp
2015-05-19 20:32:43,424 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605307.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605307
2015-05-19 20:32:43,505 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605308.tmp
2015-05-19 20:36:12,832 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605308.tmp
2015-05-19 20:36:12,859 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605308.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605308
2015-05-19 20:36:12,945 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605309.tmp
2015-05-19 20:40:19,285 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605309.tmp
2015-05-19 20:40:19,330 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605309.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605309
2015-05-19 20:40:19,392 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605310.tmp
2015-05-19 20:45:37,886 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605310.tmp
2015-05-19 20:45:37,943 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605310.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605310
2015-05-19 20:45:37,995 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605311.tmp
2015-05-19 20:51:02,556 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605311.tmp
2015-05-19 20:51:02,602 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605311.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605311
2015-05-19 20:51:02,646 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605312.tmp
2015-05-19 20:59:57,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605312.tmp
2015-05-19 20:59:57,619 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605312.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605312
2015-05-19 20:59:57,686 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605313.tmp
2015-05-19 21:06:19,285 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605313.tmp
2015-05-19 21:06:19,312 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605313.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605313
2015-05-19 21:06:19,356 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605314.tmp
2015-05-19 21:12:20,039 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605314.tmp
2015-05-19 21:12:20,075 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605314.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605314
2015-05-19 21:12:20,155 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605315.tmp
2015-05-19 21:18:17,729 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605315.tmp
2015-05-19 21:18:17,766 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605315.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605315
2015-05-19 21:18:17,842 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605316.tmp
2015-05-19 21:28:24,852 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605316.tmp
2015-05-19 21:28:24,893 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605316.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605316
2015-05-19 21:28:24,972 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605317.tmp
2015-05-19 21:36:37,811 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605317.tmp
2015-05-19 21:36:37,844 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605317.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605317
2015-05-19 21:36:37,897 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605318.tmp
15/05/19 12:45:04 INFO Worker: Asked to kill executor app-20150519055417-0015/1
15/05/19 12:45:04 INFO ExecutorRunner: Runner thread for executor app-20150519055417-0015/1 interrupted
15/05/19 12:45:04 INFO ExecutorRunner: Killing process!
15/05/19 12:45:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150519055417-0015/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/19 12:45:04 INFO Worker: Executor app-20150519055417-0015/1 finished with state KILLED exitStatus 1
15/05/19 12:45:04 INFO Worker: Cleaning up local directories for application app-20150519055417-0015
15/05/19 12:45:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A56141-58#1269839894] was not delivered. [15] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/19 12:45:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42673
]
15/05/19 12:45:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42673
]
15/05/19 12:45:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42673]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42673
]
15/05/19 12:45:26 INFO Worker: Asked to launch executor app-20150519124526-0016/1 for PTITwitterStream
15/05/19 12:45:26 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=49238" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:49238/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150519124526-0016" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-19 21:46:52,606 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605318.tmp
2015-05-19 21:46:52,659 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605318.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605318
2015-05-19 21:46:52,749 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605319.tmp
2015-05-19 22:07:53,609 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605319.tmp
2015-05-19 22:07:53,662 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605319.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605319
2015-05-19 22:07:53,711 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605320.tmp
2015-05-19 22:32:13,758 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605320.tmp
2015-05-19 22:32:13,802 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605320.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605320
2015-05-19 22:32:13,853 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605321.tmp
2015-05-19 23:02:40,353 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605321.tmp
2015-05-19 23:02:40,395 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605321.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605321
2015-05-19 23:02:40,482 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605322.tmp
2015-05-19 23:30:19,637 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605322.tmp
2015-05-19 23:30:19,685 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605322.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605322
2015-05-19 23:30:19,781 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605323.tmp
2015-05-19 23:50:38,457 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605323.tmp
2015-05-19 23:50:38,509 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605323.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605323
2015-05-19 23:50:38,585 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605324.tmp
15/05/19 15:00:03 INFO Worker: Asked to kill executor app-20150519124526-0016/1
15/05/19 15:00:03 INFO ExecutorRunner: Runner thread for executor app-20150519124526-0016/1 interrupted
15/05/19 15:00:03 INFO ExecutorRunner: Killing process!
15/05/19 15:00:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150519124526-0016/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/19 15:00:03 INFO Worker: Executor app-20150519124526-0016/1 finished with state KILLED exitStatus 1
15/05/19 15:00:03 INFO Worker: Cleaning up local directories for application app-20150519124526-0016
15/05/19 15:00:03 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A57580-62#267954399] was not delivered. [16] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/19 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44119
]
15/05/19 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44119
]
15/05/19 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44119]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44119
]
15/05/19 15:00:15 INFO Worker: Asked to launch executor app-20150519150015-0017/1 for PTITwitterStream
15/05/19 15:00:15 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=34606" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:34606/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150519150015-0017" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-20 00:00:16,287 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-20 00:00:16,325 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016288.tmp
2015-05-20 00:26:11,556 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016288.tmp
2015-05-20 00:26:11,607 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016288.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016288
2015-05-20 00:26:11,670 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016289.tmp
2015-05-20 00:45:45,319 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016289.tmp
2015-05-20 00:45:45,371 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016289.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016289
2015-05-20 00:45:45,447 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016290.tmp
2015-05-20 00:59:54,284 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605324.tmp at 1432065594283
2015-05-20 00:59:54,291 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605324.tmp
2015-05-20 00:59:54,329 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605324.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150519/user_tweets.1431975605324
2015-05-20 00:59:54,336 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-20 01:14:51,792 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016290.tmp
2015-05-20 01:14:51,833 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016290.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016290
2015-05-20 01:14:51,884 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016291.tmp
2015-05-20 02:29:47,528 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016291.tmp
2015-05-20 02:29:47,572 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016291.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016291
2015-05-20 02:29:47,657 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016292.tmp
2015-05-20 06:03:37,537 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016292.tmp
2015-05-20 06:03:37,583 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016292.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016292
2015-05-20 06:03:37,688 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016293.tmp
2015-05-20 07:48:48,422 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016293.tmp
2015-05-20 07:48:48,478 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016293.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016293
2015-05-20 07:48:48,552 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016294.tmp
15/05/19 23:11:04 INFO Worker: Asked to kill executor app-20150519150015-0017/1
15/05/19 23:11:04 INFO ExecutorRunner: Runner thread for executor app-20150519150015-0017/1 interrupted
15/05/19 23:11:04 INFO ExecutorRunner: Killing process!
15/05/19 23:11:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150519150015-0017/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/19 23:11:04 INFO Worker: Executor app-20150519150015-0017/1 finished with state KILLED exitStatus 1
15/05/19 23:11:04 INFO Worker: Cleaning up local directories for application app-20150519150015-0017
15/05/19 23:11:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A38619-66#444023679] was not delivered. [17] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/19 23:11:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:43726
]
15/05/19 23:11:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:43726
]
15/05/19 23:11:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:43726]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:43726
]
15/05/19 23:11:35 INFO Worker: Asked to launch executor app-20150519231135-0018/1 for PTITwitterStream
15/05/19 23:11:36 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=42160" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:42160/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150519231135-0018" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-20 09:25:52,869 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016294.tmp
2015-05-20 09:25:52,916 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016294.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016294
2015-05-20 09:25:53,005 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016295.tmp
2015-05-20 10:59:20,716 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016295.tmp
2015-05-20 10:59:20,749 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016295.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016295
2015-05-20 10:59:20,789 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016296.tmp
2015-05-20 12:41:50,418 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016296.tmp
2015-05-20 12:41:50,470 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016296.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016296
2015-05-20 12:41:50,549 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016297.tmp
2015-05-20 13:21:46,279 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016297.tmp
2015-05-20 13:21:46,315 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016297.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016297
2015-05-20 13:21:46,363 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016298.tmp
2015-05-20 14:30:11,904 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016298.tmp
2015-05-20 14:30:11,959 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016298.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016298
2015-05-20 14:30:12,041 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016299.tmp
2015-05-20 14:39:15,890 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016299.tmp
2015-05-20 14:39:15,918 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016299.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016299
2015-05-20 14:39:15,970 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016300.tmp
2015-05-20 14:49:29,852 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016300.tmp
2015-05-20 14:49:29,878 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016300.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016300
2015-05-20 14:49:29,937 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016301.tmp
2015-05-20 15:01:24,007 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016301.tmp
2015-05-20 15:01:24,056 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016301.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016301
2015-05-20 15:01:24,105 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016302.tmp
2015-05-20 15:11:40,074 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016302.tmp
2015-05-20 15:11:40,122 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016302.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016302
2015-05-20 15:11:40,205 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016303.tmp
2015-05-20 15:16:22,544 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016303.tmp
2015-05-20 15:16:22,586 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016303.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016303
2015-05-20 15:16:22,687 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016304.tmp
2015-05-20 15:21:59,163 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016304.tmp
2015-05-20 15:21:59,212 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016304.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016304
2015-05-20 15:21:59,252 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016305.tmp
2015-05-20 15:26:53,750 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016305.tmp
2015-05-20 15:26:53,799 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016305.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016305
2015-05-20 15:26:53,867 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016306.tmp
2015-05-20 15:30:30,200 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016306.tmp
2015-05-20 15:30:30,229 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016306.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016306
2015-05-20 15:30:30,324 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016307.tmp
2015-05-20 15:33:48,623 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016307.tmp
2015-05-20 15:33:48,667 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016307.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016307
2015-05-20 15:33:48,740 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016308.tmp
15/05/20 06:35:03 INFO Worker: Asked to kill executor app-20150519231135-0018/1
15/05/20 06:35:03 INFO ExecutorRunner: Runner thread for executor app-20150519231135-0018/1 interrupted
15/05/20 06:35:03 INFO ExecutorRunner: Killing process!
15/05/20 06:35:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150519231135-0018/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/20 06:35:04 INFO Worker: Executor app-20150519231135-0018/1 finished with state KILLED exitStatus 1
15/05/20 06:35:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A41511-70#449921095] was not delivered. [18] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/20 06:35:04 INFO Worker: Cleaning up local directories for application app-20150519231135-0018
15/05/20 06:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50345
]
15/05/20 06:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50345
]
15/05/20 06:35:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50345]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50345
]
15/05/20 06:35:44 INFO Worker: Asked to launch executor app-20150520063544-0019/1 for PTITwitterStream
15/05/20 06:35:44 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=45163" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:45163/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150520063544-0019" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-20 15:42:31,519 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016308.tmp
2015-05-20 15:42:31,565 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016308.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016308
2015-05-20 15:42:31,631 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016309.tmp
2015-05-20 15:54:57,781 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016309.tmp
2015-05-20 15:54:57,826 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016309.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016309
2015-05-20 15:54:57,881 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016310.tmp
2015-05-20 16:06:59,026 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016310.tmp
2015-05-20 16:06:59,100 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016310.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016310
2015-05-20 16:06:59,173 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016311.tmp
2015-05-20 16:34:51,440 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016311.tmp
2015-05-20 16:34:51,491 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016311.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016311
2015-05-20 16:34:51,571 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016312.tmp
2015-05-20 16:56:29,278 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016312.tmp
2015-05-20 16:56:29,330 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016312.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016312
2015-05-20 16:56:29,425 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016313.tmp
2015-05-20 17:12:54,777 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016313.tmp
2015-05-20 17:12:54,802 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016313.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016313
2015-05-20 17:12:54,870 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016314.tmp
2015-05-20 17:38:24,955 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016314.tmp
2015-05-20 17:38:25,021 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016314.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016314
2015-05-20 17:38:25,096 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016315.tmp
2015-05-20 17:50:04,255 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016315.tmp
2015-05-20 17:50:04,283 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016315.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016315
2015-05-20 17:50:04,345 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016316.tmp
2015-05-20 18:09:36,054 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016316.tmp
2015-05-20 18:09:36,096 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016316.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016316
2015-05-20 18:09:36,162 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016317.tmp
2015-05-20 18:26:19,624 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016317.tmp
2015-05-20 18:26:19,659 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016317.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016317
2015-05-20 18:26:19,700 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016318.tmp
2015-05-20 18:42:15,189 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016318.tmp
2015-05-20 18:42:15,232 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016318.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016318
2015-05-20 18:42:15,299 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016319.tmp
2015-05-20 19:05:18,388 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016319.tmp
2015-05-20 19:05:18,438 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016319.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016319
2015-05-20 19:05:18,520 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016320.tmp
2015-05-20 19:22:19,126 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016320.tmp
2015-05-20 19:22:19,163 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016320.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016320
2015-05-20 19:22:19,232 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016321.tmp
2015-05-20 19:48:51,730 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016321.tmp
2015-05-20 19:48:51,780 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016321.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016321
2015-05-20 19:48:51,830 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016322.tmp
2015-05-20 20:04:11,368 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016322.tmp
2015-05-20 20:04:11,409 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016322.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016322
2015-05-20 20:04:11,517 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016323.tmp
2015-05-20 20:10:54,202 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016323.tmp
2015-05-20 20:10:54,247 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016323.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016323
2015-05-20 20:10:54,323 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016324.tmp
2015-05-20 20:23:55,719 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016324.tmp
2015-05-20 20:23:55,747 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016324.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016324
2015-05-20 20:23:55,818 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016325.tmp
2015-05-20 20:32:03,635 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016325.tmp
2015-05-20 20:32:03,685 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016325.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016325
2015-05-20 20:32:03,761 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016326.tmp
2015-05-20 20:37:10,307 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016326.tmp
2015-05-20 20:37:10,347 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016326.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016326
2015-05-20 20:37:10,422 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016327.tmp
2015-05-20 20:47:47,497 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016327.tmp
2015-05-20 20:47:47,529 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016327.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016327
2015-05-20 20:47:47,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016328.tmp
2015-05-20 21:06:54,270 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016328.tmp
2015-05-20 21:06:54,320 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016328.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016328
2015-05-20 21:06:54,450 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016329.tmp
2015-05-20 21:28:21,027 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016329.tmp
2015-05-20 21:28:21,077 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016329.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016329
2015-05-20 21:28:21,163 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016330.tmp
2015-05-20 21:44:51,499 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016330.tmp
2015-05-20 21:44:51,529 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016330.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016330
2015-05-20 21:44:51,604 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016331.tmp
2015-05-20 22:03:29,004 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016331.tmp
2015-05-20 22:03:29,044 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016331.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016331
2015-05-20 22:03:29,082 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016332.tmp
2015-05-20 22:11:17,913 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016332.tmp
2015-05-20 22:11:17,959 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016332.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016332
2015-05-20 22:11:18,026 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016333.tmp
2015-05-20 22:17:18,640 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016333.tmp
2015-05-20 22:17:18,670 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016333.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016333
2015-05-20 22:17:18,755 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016334.tmp
2015-05-20 22:24:25,452 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016334.tmp
2015-05-20 22:24:25,488 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016334.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016334
2015-05-20 22:24:25,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016335.tmp
15/05/20 13:29:04 INFO Worker: Asked to kill executor app-20150520063544-0019/1
15/05/20 13:29:04 INFO ExecutorRunner: Runner thread for executor app-20150520063544-0019/1 interrupted
15/05/20 13:29:04 INFO ExecutorRunner: Killing process!
15/05/20 13:29:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150520063544-0019/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/20 13:29:04 INFO Worker: Executor app-20150520063544-0019/1 finished with state KILLED exitStatus 1
15/05/20 13:29:04 INFO Worker: Cleaning up local directories for application app-20150520063544-0019
15/05/20 13:29:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A42759-74#-1272484630] was not delivered. [19] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/20 13:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59448
]
15/05/20 13:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59448
]
15/05/20 13:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59448]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59448
]
15/05/20 13:29:56 INFO Worker: Asked to launch executor app-20150520132956-0020/1 for PTITwitterStream
15/05/20 13:29:56 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=43118" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:43118/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150520132956-0020" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-20 22:30:21,112 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016335.tmp
2015-05-20 22:30:21,144 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016335.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016335
2015-05-20 22:30:21,222 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016336.tmp
2015-05-20 22:35:26,670 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016336.tmp
2015-05-20 22:35:26,716 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016336.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016336
2015-05-20 22:35:26,783 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016337.tmp
2015-05-20 22:38:28,056 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016337.tmp
2015-05-20 22:38:28,094 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016337.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016337
2015-05-20 22:38:28,144 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016338.tmp
2015-05-20 22:42:39,545 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016338.tmp
2015-05-20 22:42:39,573 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016338.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016338
2015-05-20 22:42:39,622 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016339.tmp
2015-05-20 22:48:35,315 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016339.tmp
2015-05-20 22:48:35,356 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016339.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016339
2015-05-20 22:48:35,440 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016340.tmp
2015-05-20 22:53:52,906 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016340.tmp
2015-05-20 22:53:52,957 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016340.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016340
2015-05-20 22:53:53,042 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016341.tmp
2015-05-20 22:59:30,623 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016341.tmp
2015-05-20 22:59:30,662 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016341.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016341
2015-05-20 22:59:30,752 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016342.tmp
2015-05-20 23:02:05,946 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016342.tmp
2015-05-20 23:02:05,980 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016342.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016342
2015-05-20 23:02:06,029 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016343.tmp
2015-05-20 23:04:54,272 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016343.tmp
2015-05-20 23:04:54,319 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016343.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016343
2015-05-20 23:04:54,397 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016344.tmp
2015-05-20 23:07:30,579 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016344.tmp
2015-05-20 23:07:30,609 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016344.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016344
2015-05-20 23:07:30,659 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016345.tmp
2015-05-20 23:10:34,010 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016345.tmp
2015-05-20 23:10:34,054 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016345.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016345
2015-05-20 23:10:34,132 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016346.tmp
2015-05-20 23:14:04,447 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016346.tmp
2015-05-20 23:14:04,485 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016346.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016346
2015-05-20 23:14:04,563 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016347.tmp
2015-05-20 23:20:41,157 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016347.tmp
2015-05-20 23:20:41,206 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016347.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016347
2015-05-20 23:20:41,281 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016348.tmp
2015-05-20 23:33:24,524 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016348.tmp
2015-05-20 23:33:24,595 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016348.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016348
2015-05-20 23:33:24,691 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016349.tmp
2015-05-20 23:48:38,078 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016349.tmp
2015-05-20 23:48:38,133 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016349.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016349
2015-05-20 23:48:38,175 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016350.tmp
15/05/20 15:00:03 INFO Worker: Asked to kill executor app-20150520132956-0020/1
15/05/20 15:00:03 INFO ExecutorRunner: Runner thread for executor app-20150520132956-0020/1 interrupted
15/05/20 15:00:03 INFO ExecutorRunner: Killing process!
15/05/20 15:00:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150520132956-0020/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/20 15:00:03 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A45118-78#-1465398933] was not delivered. [20] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/20 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:36875
]
15/05/20 15:00:03 INFO Worker: Executor app-20150520132956-0020/1 finished with state KILLED exitStatus 1
15/05/20 15:00:03 INFO Worker: Cleaning up local directories for application app-20150520132956-0020
15/05/20 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:36875
]
15/05/20 15:00:03 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:36875]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:36875
]
15/05/20 15:00:14 INFO Worker: Asked to launch executor app-20150520150014-0021/1 for PTITwitterStream
15/05/20 15:00:14 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=33024" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:33024/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150520150014-0021" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-21 00:00:16,270 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-21 00:00:16,306 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416271.tmp
2015-05-21 00:23:47,449 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416271.tmp
2015-05-21 00:23:47,499 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416271.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416271
2015-05-21 00:23:47,585 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416272.tmp
2015-05-21 00:59:54,264 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016350.tmp at 1432151994263
2015-05-21 00:59:54,269 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016350.tmp
2015-05-21 00:59:54,297 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016350.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150520/user_tweets.1432062016350
2015-05-21 00:59:54,301 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-21 01:07:44,702 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416272.tmp
2015-05-21 01:07:44,759 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416272.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416272
2015-05-21 01:07:44,842 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416273.tmp
2015-05-21 01:25:55,333 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416273.tmp
2015-05-21 01:25:55,376 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416273.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416273
2015-05-21 01:25:55,472 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416274.tmp
2015-05-21 01:41:56,920 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416274.tmp
2015-05-21 01:41:56,949 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416274.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416274
2015-05-21 01:41:57,034 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416275.tmp
2015-05-21 02:14:06,651 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416275.tmp
2015-05-21 02:14:06,686 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416275.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416275
2015-05-21 02:14:06,774 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416276.tmp
2015-05-21 02:59:58,061 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416276.tmp
2015-05-21 02:59:58,097 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416276.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416276
2015-05-21 02:59:58,149 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416277.tmp
15/05/20 22:27:04 INFO Worker: Asked to kill executor app-20150520150014-0021/1
15/05/20 22:27:04 INFO ExecutorRunner: Runner thread for executor app-20150520150014-0021/1 interrupted
15/05/20 22:27:04 INFO ExecutorRunner: Killing process!
15/05/20 22:27:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150520150014-0021/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/20 22:27:04 INFO Worker: Executor app-20150520150014-0021/1 finished with state KILLED exitStatus 1
15/05/20 22:27:04 INFO Worker: Cleaning up local directories for application app-20150520150014-0021
15/05/20 22:27:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A53306-82#-886797855] was not delivered. [21] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/20 22:27:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50897
]
15/05/20 22:27:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50897
]
15/05/20 22:27:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:50897]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:50897
]
15/05/20 22:28:06 INFO Worker: Asked to launch executor app-20150520222806-0022/1 for PTITwitterStream
15/05/20 22:28:06 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=33992" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:33992/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150520222806-0022" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-21 07:51:25,972 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416277.tmp
2015-05-21 07:51:26,010 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416277.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416277
2015-05-21 07:51:26,087 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416278.tmp
2015-05-21 10:06:40,524 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416278.tmp
2015-05-21 10:06:40,558 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416278.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416278
2015-05-21 10:06:40,628 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416279.tmp
2015-05-21 11:00:26,868 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416279.tmp
2015-05-21 11:00:26,903 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416279.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416279
2015-05-21 11:00:26,979 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416280.tmp
2015-05-21 11:23:28,832 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416280.tmp
2015-05-21 11:23:28,868 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416280.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416280
2015-05-21 11:23:28,907 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416281.tmp
2015-05-21 11:37:00,194 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416281.tmp
2015-05-21 11:37:00,233 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416281.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416281
2015-05-21 11:37:00,303 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416282.tmp
2015-05-21 11:55:20,888 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416282.tmp
2015-05-21 11:55:20,940 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416282.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416282
2015-05-21 11:55:21,015 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416283.tmp
2015-05-21 12:06:00,018 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416283.tmp
2015-05-21 12:06:00,064 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416283.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416283
2015-05-21 12:06:00,104 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416284.tmp
2015-05-21 12:11:06,573 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416284.tmp
2015-05-21 12:11:06,609 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416284.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416284
2015-05-21 12:11:06,674 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416285.tmp
2015-05-21 12:15:13,019 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416285.tmp
2015-05-21 12:15:13,058 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416285.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416285
2015-05-21 12:15:13,095 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416286.tmp
2015-05-21 12:23:16,897 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416286.tmp
2015-05-21 12:23:16,935 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416286.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416286
2015-05-21 12:23:16,999 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416287.tmp
2015-05-21 12:33:42,029 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416287.tmp
2015-05-21 12:33:42,053 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416287.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416287
2015-05-21 12:33:42,085 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416288.tmp
2015-05-21 12:43:08,037 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416288.tmp
2015-05-21 12:43:08,090 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416288.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416288
2015-05-21 12:43:08,151 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416289.tmp
2015-05-21 12:52:07,979 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416289.tmp
2015-05-21 12:52:08,017 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416289.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416289
2015-05-21 12:52:08,068 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416290.tmp
2015-05-21 12:55:50,392 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416290.tmp
2015-05-21 12:55:50,425 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416290.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416290
2015-05-21 12:55:50,491 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416291.tmp
2015-05-21 12:58:02,649 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416291.tmp
2015-05-21 12:58:02,680 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416291.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416291
2015-05-21 12:58:02,745 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416292.tmp
2015-05-21 13:02:16,122 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416292.tmp
2015-05-21 13:02:16,158 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416292.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416292
2015-05-21 13:02:16,208 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416293.tmp
2015-05-21 13:16:07,523 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416293.tmp
2015-05-21 13:16:07,560 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416293.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416293
2015-05-21 13:16:07,621 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416294.tmp
2015-05-21 13:24:20,412 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416294.tmp
2015-05-21 13:24:20,442 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416294.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416294
2015-05-21 13:24:20,512 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416295.tmp
2015-05-21 13:34:51,437 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416295.tmp
2015-05-21 13:34:51,470 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416295.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416295
2015-05-21 13:34:51,545 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416296.tmp
2015-05-21 13:50:28,903 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416296.tmp
2015-05-21 13:50:28,948 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416296.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416296
2015-05-21 13:50:29,019 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416297.tmp
2015-05-21 14:03:54,139 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416297.tmp
2015-05-21 14:03:54,162 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416297.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416297
2015-05-21 14:03:54,213 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416298.tmp
2015-05-21 14:17:56,416 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416298.tmp
2015-05-21 14:17:56,455 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416298.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416298
2015-05-21 14:17:56,497 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416299.tmp
15/05/21 05:25:03 INFO Worker: Asked to kill executor app-20150520222806-0022/1
15/05/21 05:25:03 INFO ExecutorRunner: Runner thread for executor app-20150520222806-0022/1 interrupted
15/05/21 05:25:03 INFO ExecutorRunner: Killing process!
15/05/21 05:25:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150520222806-0022/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/21 05:25:04 INFO Worker: Executor app-20150520222806-0022/1 finished with state KILLED exitStatus 1
15/05/21 05:25:04 INFO Worker: Cleaning up local directories for application app-20150520222806-0022
15/05/21 05:25:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A53485-86#-881827499] was not delivered. [22] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/21 05:25:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49249
]
15/05/21 05:25:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49249
]
15/05/21 05:25:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:49249]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:49249
]
15/05/21 05:26:13 INFO Worker: Asked to launch executor app-20150521052613-0023/1 for PTITwitterStream
15/05/21 05:26:13 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=42522" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:42522/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150521052613-0023" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-21 14:35:26,994 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416299.tmp
2015-05-21 14:35:27,030 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416299.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416299
2015-05-21 14:35:27,100 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416300.tmp
2015-05-21 14:53:04,508 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416300.tmp
2015-05-21 14:53:04,537 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416300.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416300
2015-05-21 14:53:04,631 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416301.tmp
2015-05-21 15:05:35,723 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416301.tmp
2015-05-21 15:05:35,776 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416301.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416301
2015-05-21 15:05:35,816 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416302.tmp
2015-05-21 15:35:08,156 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416302.tmp
2015-05-21 15:35:08,225 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416302.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416302
2015-05-21 15:35:08,304 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416303.tmp
2015-05-21 15:47:58,231 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416303.tmp
2015-05-21 15:47:58,269 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416303.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416303
2015-05-21 15:47:58,322 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416304.tmp
2015-05-21 15:56:19,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416304.tmp
2015-05-21 15:56:19,183 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416304.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416304
2015-05-21 15:56:19,247 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416305.tmp
2015-05-21 16:07:23,187 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416305.tmp
2015-05-21 16:07:23,213 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416305.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416305
2015-05-21 16:07:23,250 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416306.tmp
2015-05-21 16:18:28,363 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416306.tmp
2015-05-21 16:18:28,397 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416306.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416306
2015-05-21 16:18:28,488 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416307.tmp
2015-05-21 16:25:28,136 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416307.tmp
2015-05-21 16:25:28,172 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416307.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416307
2015-05-21 16:25:28,245 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416308.tmp
2015-05-21 16:39:42,539 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416308.tmp
2015-05-21 16:39:42,589 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416308.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416308
2015-05-21 16:39:42,656 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416309.tmp
2015-05-21 16:52:12,755 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416309.tmp
2015-05-21 16:52:12,778 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416309.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416309
2015-05-21 16:52:12,823 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416310.tmp
2015-05-21 17:05:39,130 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416310.tmp
2015-05-21 17:05:39,157 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416310.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416310
2015-05-21 17:05:39,200 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416311.tmp
2015-05-21 17:13:26,978 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416311.tmp
2015-05-21 17:13:27,013 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416311.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416311
2015-05-21 17:13:27,056 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416312.tmp
2015-05-21 17:19:57,688 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416312.tmp
2015-05-21 17:19:57,719 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416312.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416312
2015-05-21 17:19:57,757 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416313.tmp
2015-05-21 17:31:25,866 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416313.tmp
2015-05-21 17:31:25,909 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416313.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416313
2015-05-21 17:31:25,984 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416314.tmp
2015-05-21 17:43:03,092 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416314.tmp
2015-05-21 17:43:03,112 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416314.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416314
2015-05-21 17:43:03,194 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416315.tmp
2015-05-21 18:06:03,284 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416315.tmp
2015-05-21 18:06:03,310 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416315.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416315
2015-05-21 18:06:03,382 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416316.tmp
2015-05-21 18:22:49,003 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416316.tmp
2015-05-21 18:22:49,055 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416316.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416316
2015-05-21 18:22:49,136 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416317.tmp
2015-05-21 18:50:33,364 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416317.tmp
2015-05-21 18:50:33,406 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416317.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416317
2015-05-21 18:50:33,447 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416318.tmp
2015-05-21 19:35:54,873 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416318.tmp
2015-05-21 19:35:54,918 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416318.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416318
2015-05-21 19:35:54,963 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416319.tmp
2015-05-21 20:03:24,389 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416319.tmp
2015-05-21 20:03:24,438 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416319.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416319
2015-05-21 20:03:24,501 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416320.tmp
2015-05-21 20:32:45,116 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416320.tmp
2015-05-21 20:32:45,165 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416320.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416320
2015-05-21 20:32:45,206 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416321.tmp
2015-05-21 20:46:28,426 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416321.tmp
2015-05-21 20:46:28,479 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416321.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416321
2015-05-21 20:46:28,544 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416322.tmp
2015-05-21 20:53:17,224 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416322.tmp
2015-05-21 20:53:17,271 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416322.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416322
2015-05-21 20:53:17,358 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416323.tmp
2015-05-21 21:02:37,171 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416323.tmp
2015-05-21 21:02:37,222 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416323.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416323
2015-05-21 21:02:37,297 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416324.tmp
2015-05-21 21:15:02,457 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416324.tmp
2015-05-21 21:15:02,493 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416324.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416324
2015-05-21 21:15:02,536 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416325.tmp
2015-05-21 21:20:27,038 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416325.tmp
2015-05-21 21:20:27,083 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416325.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416325
2015-05-21 21:20:27,151 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416326.tmp
2015-05-21 21:25:38,663 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416326.tmp
2015-05-21 21:25:38,698 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416326.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416326
2015-05-21 21:25:38,767 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416327.tmp
2015-05-21 21:31:34,349 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416327.tmp
2015-05-21 21:31:34,384 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416327.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416327
2015-05-21 21:31:34,437 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416328.tmp
15/05/21 12:39:04 INFO Worker: Asked to kill executor app-20150521052613-0023/1
15/05/21 12:39:04 INFO ExecutorRunner: Runner thread for executor app-20150521052613-0023/1 interrupted
15/05/21 12:39:04 INFO ExecutorRunner: Killing process!
15/05/21 12:39:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150521052613-0023/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/21 12:39:04 INFO Worker: Executor app-20150521052613-0023/1 finished with state KILLED exitStatus 1
15/05/21 12:39:04 INFO Worker: Cleaning up local directories for application app-20150521052613-0023
15/05/21 12:39:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A54170-90#864199049] was not delivered. [23] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/21 12:39:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42425
]
15/05/21 12:39:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42425
]
15/05/21 12:39:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:42425]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:42425
]
15/05/21 12:39:23 INFO Worker: Asked to launch executor app-20150521123923-0024/1 for PTITwitterStream
15/05/21 12:39:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=33854" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:33854/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150521123923-0024" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-21 21:41:58,483 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416328.tmp
2015-05-21 21:41:58,525 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416328.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416328
2015-05-21 21:41:58,576 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416329.tmp
2015-05-21 21:44:46,799 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416329.tmp
2015-05-21 21:44:46,828 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416329.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416329
2015-05-21 21:44:46,889 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416330.tmp
2015-05-21 21:47:47,140 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416330.tmp
2015-05-21 21:47:47,170 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416330.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416330
2015-05-21 21:47:47,217 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416331.tmp
2015-05-21 21:52:41,672 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416331.tmp
2015-05-21 21:52:41,719 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416331.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416331
2015-05-21 21:52:41,803 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416332.tmp
2015-05-21 21:58:39,345 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416332.tmp
2015-05-21 21:58:39,392 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416332.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416332
2015-05-21 21:58:39,470 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416333.tmp
2015-05-21 22:05:22,136 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416333.tmp
2015-05-21 22:05:22,171 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416333.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416333
2015-05-21 22:05:22,251 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416334.tmp
2015-05-21 22:13:44,049 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416334.tmp
2015-05-21 22:13:44,094 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416334.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416334
2015-05-21 22:13:44,168 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416335.tmp
2015-05-21 22:19:38,734 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416335.tmp
2015-05-21 22:19:38,776 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416335.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416335
2015-05-21 22:19:38,824 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416336.tmp
2015-05-21 22:25:01,370 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416336.tmp
2015-05-21 22:25:01,408 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416336.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416336
2015-05-21 22:25:01,513 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416337.tmp
2015-05-21 22:31:55,189 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416337.tmp
2015-05-21 22:31:55,236 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416337.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416337
2015-05-21 22:31:55,281 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416338.tmp
2015-05-21 22:42:32,291 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416338.tmp
2015-05-21 22:42:32,330 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416338.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416338
2015-05-21 22:42:32,410 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416339.tmp
2015-05-21 22:53:09,391 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416339.tmp
2015-05-21 22:53:09,427 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416339.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416339
2015-05-21 22:53:09,508 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416340.tmp
2015-05-21 22:59:46,157 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416340.tmp
2015-05-21 22:59:46,196 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416340.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416340
2015-05-21 22:59:46,244 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416341.tmp
2015-05-21 23:26:36,451 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416341.tmp
2015-05-21 23:26:36,511 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416341.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416341
2015-05-21 23:26:36,596 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416342.tmp
2015-05-21 23:46:38,324 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416342.tmp
2015-05-21 23:46:38,373 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416342.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416342
2015-05-21 23:46:38,452 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416343.tmp
2015-05-21 23:55:15,348 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416343.tmp
2015-05-21 23:55:15,392 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416343.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416343
2015-05-21 23:55:15,468 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416344.tmp
15/05/21 15:00:03 INFO Worker: Asked to kill executor app-20150521123923-0024/1
15/05/21 15:00:03 INFO ExecutorRunner: Runner thread for executor app-20150521123923-0024/1 interrupted
15/05/21 15:00:03 INFO ExecutorRunner: Killing process!
15/05/21 15:00:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150521123923-0024/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
2015-05-22 00:00:03,753 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-22 00:00:03,868 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803754.tmp
15/05/21 15:00:04 INFO Worker: Executor app-20150521123923-0024/1 finished with state KILLED exitStatus 1
15/05/21 15:00:04 INFO Worker: Cleaning up local directories for application app-20150521123923-0024
15/05/21 15:00:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A57759-94#-889343877] was not delivered. [24] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/21 15:00:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33884
]
15/05/21 15:00:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33884
]
15/05/21 15:00:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:33884]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:33884
]
15/05/21 15:00:16 INFO Worker: Asked to launch executor app-20150521150016-0025/1 for PTITwitterStream
15/05/21 15:00:16 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=43917" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:43917/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150521150016-0025" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-22 00:28:03,253 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803754.tmp
2015-05-22 00:28:03,300 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803754.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803754
2015-05-22 00:28:03,361 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803755.tmp
2015-05-22 00:59:54,752 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416344.tmp at 1432238394751
2015-05-22 00:59:54,756 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416344.tmp
2015-05-22 00:59:54,801 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416344.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150521/user_tweets.1432148416344
2015-05-22 00:59:54,807 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-22 01:17:54,987 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803755.tmp
2015-05-22 01:17:55,043 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803755.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803755
2015-05-22 01:17:55,124 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803756.tmp
2015-05-22 02:20:00,263 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803756.tmp
2015-05-22 02:20:00,308 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803756.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803756
2015-05-22 02:20:00,394 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803757.tmp
2015-05-22 04:13:30,039 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803757.tmp
2015-05-22 04:13:30,079 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803757.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803757
2015-05-22 04:13:30,162 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803758.tmp
15/05/21 22:47:03 INFO Worker: Asked to kill executor app-20150521150016-0025/1
15/05/21 22:47:03 INFO ExecutorRunner: Runner thread for executor app-20150521150016-0025/1 interrupted
15/05/21 22:47:03 INFO ExecutorRunner: Killing process!
15/05/21 22:47:03 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150521150016-0025/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/21 22:47:04 INFO Worker: Executor app-20150521150016-0025/1 finished with state KILLED exitStatus 1
15/05/21 22:47:04 INFO Worker: Cleaning up local directories for application app-20150521150016-0025
15/05/21 22:47:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A41526-98#1469198672] was not delivered. [25] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/21 22:47:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:56491
]
15/05/21 22:47:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:56491
]
15/05/21 22:47:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:56491]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:56491
]
15/05/21 22:47:35 INFO Worker: Asked to launch executor app-20150521224735-0026/1 for PTITwitterStream
15/05/21 22:47:35 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=50506" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:50506/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150521224735-0026" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-22 08:01:25,016 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803758.tmp
2015-05-22 08:01:25,067 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803758.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803758
2015-05-22 08:01:25,148 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803759.tmp
2015-05-22 09:55:55,630 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803759.tmp
2015-05-22 09:55:55,663 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803759.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803759
2015-05-22 09:55:55,751 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803760.tmp
2015-05-22 10:14:40,210 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803760.tmp
2015-05-22 10:14:40,245 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803760.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803760
2015-05-22 10:14:40,319 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803761.tmp
2015-05-22 10:54:25,364 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803761.tmp
2015-05-22 10:54:25,407 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803761.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803761
2015-05-22 10:54:25,492 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803762.tmp
2015-05-22 11:37:52,627 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803762.tmp
2015-05-22 11:37:52,666 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803762.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803762
2015-05-22 11:37:52,740 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803763.tmp
2015-05-22 11:57:05,318 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803763.tmp
2015-05-22 11:57:05,350 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803763.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803763
2015-05-22 11:57:05,385 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803764.tmp
2015-05-22 12:25:40,595 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803764.tmp
2015-05-22 12:25:40,642 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803764.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803764
2015-05-22 12:25:40,726 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803765.tmp
2015-05-22 13:11:32,163 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803765.tmp
2015-05-22 13:11:32,200 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803765.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803765
2015-05-22 13:11:32,275 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803766.tmp
2015-05-22 13:23:33,432 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803766.tmp
2015-05-22 13:23:33,471 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803766.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803766
2015-05-22 13:23:33,513 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803767.tmp
2015-05-22 13:51:48,911 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803767.tmp
2015-05-22 13:51:48,950 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803767.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803767
2015-05-22 13:51:48,996 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803768.tmp
2015-05-22 14:24:38,758 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803768.tmp
2015-05-22 14:24:38,788 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803768.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803768
2015-05-22 14:24:38,823 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803769.tmp
2015-05-22 14:43:16,477 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803769.tmp
2015-05-22 14:43:16,515 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803769.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803769
2015-05-22 14:43:16,603 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803770.tmp
2015-05-22 15:37:31,295 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803770.tmp
2015-05-22 15:37:31,328 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803770.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803770
2015-05-22 15:37:31,365 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803771.tmp
15/05/22 07:07:04 INFO Worker: Asked to kill executor app-20150521224735-0026/1
15/05/22 07:07:04 INFO ExecutorRunner: Runner thread for executor app-20150521224735-0026/1 interrupted
15/05/22 07:07:04 INFO ExecutorRunner: Killing process!
15/05/22 07:07:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150521224735-0026/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/22 07:07:04 INFO Worker: Executor app-20150521224735-0026/1 finished with state KILLED exitStatus 1
15/05/22 07:07:04 INFO Worker: Cleaning up local directories for application app-20150521224735-0026
15/05/22 07:07:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A42503-102#-1457160933] was not delivered. [26] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/22 07:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44037
]
15/05/22 07:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44037
]
15/05/22 07:07:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:44037]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:44037
]
15/05/22 07:07:41 INFO Worker: Asked to launch executor app-20150522070741-0027/1 for PTITwitterStream
15/05/22 07:07:42 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=50894" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:50894/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150522070741-0027" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-22 16:43:18,985 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803771.tmp
2015-05-22 16:43:19,020 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803771.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803771
2015-05-22 16:43:19,058 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803772.tmp
2015-05-22 17:29:41,344 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803772.tmp
2015-05-22 17:29:41,405 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803772.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803772
2015-05-22 17:29:41,501 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803773.tmp
2015-05-22 18:11:50,346 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803773.tmp
2015-05-22 18:11:50,385 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803773.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803773
2015-05-22 18:11:50,468 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803774.tmp
2015-05-22 18:57:37,382 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803774.tmp
2015-05-22 18:57:37,420 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803774.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803774
2015-05-22 18:57:37,515 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803775.tmp
2015-05-22 19:08:50,454 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803775.tmp
2015-05-22 19:08:50,494 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803775.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803775
2015-05-22 19:08:50,573 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803776.tmp
2015-05-22 19:17:54,420 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803776.tmp
2015-05-22 19:17:54,465 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803776.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803776
2015-05-22 19:17:54,559 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803777.tmp
2015-05-22 19:25:37,307 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803777.tmp
2015-05-22 19:25:37,342 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803777.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803777
2015-05-22 19:25:37,384 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803778.tmp
2015-05-22 19:34:32,307 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803778.tmp
2015-05-22 19:34:32,345 (hdfs-hdfs-sink-2-call-runner-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803778.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803778
2015-05-22 19:34:32,423 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803779.tmp
2015-05-22 19:45:15,472 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803779.tmp
2015-05-22 19:45:15,519 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803779.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803779
2015-05-22 19:45:15,598 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803780.tmp
2015-05-22 19:59:40,869 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803780.tmp
2015-05-22 19:59:40,923 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803780.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803780
2015-05-22 19:59:41,001 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803781.tmp
2015-05-22 20:12:42,210 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803781.tmp
2015-05-22 20:12:42,263 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803781.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803781
2015-05-22 20:12:42,309 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803782.tmp
2015-05-22 20:25:13,462 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803782.tmp
2015-05-22 20:25:13,506 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803782.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803782
2015-05-22 20:25:13,589 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803783.tmp
2015-05-22 20:43:57,278 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803783.tmp
2015-05-22 20:43:57,314 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803783.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803783
2015-05-22 20:43:57,358 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803784.tmp
2015-05-22 20:57:10,585 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803784.tmp
2015-05-22 20:57:10,634 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803784.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803784
2015-05-22 20:57:10,720 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803785.tmp
2015-05-22 21:11:17,948 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803785.tmp
2015-05-22 21:11:17,996 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803785.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803785
2015-05-22 21:11:18,077 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803786.tmp
2015-05-22 21:23:31,216 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803786.tmp
2015-05-22 21:23:31,260 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803786.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803786
2015-05-22 21:23:31,310 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803787.tmp
2015-05-22 21:35:17,395 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803787.tmp
2015-05-22 21:35:17,423 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803787.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803787
2015-05-22 21:35:17,469 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803788.tmp
2015-05-22 21:58:19,486 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803788.tmp
2015-05-22 21:58:19,532 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803788.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803788
2015-05-22 21:58:19,576 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803789.tmp
2015-05-22 22:13:02,952 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803789.tmp
2015-05-22 22:13:03,008 (hdfs-hdfs-sink-2-call-runner-2) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803789.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803789
2015-05-22 22:13:03,068 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803790.tmp
2015-05-22 22:23:22,138 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803790.tmp
2015-05-22 22:23:22,206 (hdfs-hdfs-sink-2-call-runner-1) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803790.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803790
2015-05-22 22:23:22,283 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803791.tmp
2015-05-22 22:26:28,511 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803791.tmp
2015-05-22 22:26:28,550 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803791.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803791
2015-05-22 22:26:28,636 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803792.tmp
2015-05-22 22:34:36,445 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803792.tmp
2015-05-22 22:34:36,482 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803792.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803792
2015-05-22 22:34:36,566 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803793.tmp
2015-05-22 22:49:31,043 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803793.tmp
2015-05-22 22:49:31,083 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803793.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803793
2015-05-22 22:49:31,131 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803794.tmp
15/05/22 13:53:04 INFO Worker: Asked to kill executor app-20150522070741-0027/1
15/05/22 13:53:04 INFO ExecutorRunner: Runner thread for executor app-20150522070741-0027/1 interrupted
15/05/22 13:53:04 INFO ExecutorRunner: Killing process!
15/05/22 13:53:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150522070741-0027/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/22 13:53:04 INFO Worker: Executor app-20150522070741-0027/1 finished with state KILLED exitStatus 1
15/05/22 13:53:04 INFO Worker: Cleaning up local directories for application app-20150522070741-0027
15/05/22 13:53:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A46978-106#1642844075] was not delivered. [27] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/22 13:53:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:45502
]
15/05/22 13:53:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:45502
]
15/05/22 13:53:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:45502]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:45502
]
15/05/22 13:53:50 INFO Worker: Asked to launch executor app-20150522135350-0028/1 for PTITwitterStream
15/05/22 13:53:50 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=43128" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:43128/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150522135350-0028" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-22 23:07:14,790 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803794.tmp
2015-05-22 23:07:14,837 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803794.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803794
2015-05-22 23:07:14,888 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803795.tmp
2015-05-22 23:22:47,249 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803795.tmp
2015-05-22 23:22:47,286 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803795.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803795
2015-05-22 23:22:47,372 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803796.tmp
2015-05-22 23:43:31,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803796.tmp
2015-05-22 23:43:31,184 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803796.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803796
2015-05-22 23:43:31,275 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803797.tmp
2015-05-23 00:00:01,771 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:58)] Serializer = TEXT, UseRawLocalFileSystem = false
2015-05-23 00:00:01,900 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201771.tmp
15/05/22 15:00:09 INFO Worker: Asked to kill executor app-20150522135350-0028/1
15/05/22 15:00:09 INFO ExecutorRunner: Runner thread for executor app-20150522135350-0028/1 interrupted
15/05/22 15:00:09 INFO ExecutorRunner: Killing process!
15/05/22 15:00:09 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150522135350-0028/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/22 15:00:10 INFO Worker: Executor app-20150522135350-0028/1 finished with state KILLED exitStatus 1
15/05/22 15:00:10 INFO Worker: Cleaning up local directories for application app-20150522135350-0028
15/05/22 15:00:10 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A47908-110#-689327793] was not delivered. [28] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/22 15:00:10 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54987
]
15/05/22 15:00:10 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54987
]
15/05/22 15:00:10 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:54987]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:54987
]
15/05/22 15:00:21 INFO Worker: Asked to launch executor app-20150522150021-0029/1 for PTITwitterStream
15/05/22 15:00:21 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=55117" "-Xms1024M" "-Xmx1024M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:55117/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "1" "--app-id" "app-20150522150021-0029" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:46324/user/Worker"
2015-05-23 00:23:27,816 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201771.tmp
2015-05-23 00:23:27,868 (hdfs-hdfs-sink-2-call-runner-4) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201771.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201771
2015-05-23 00:23:27,913 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201772.tmp
2015-05-23 00:46:59,900 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201772.tmp
2015-05-23 00:46:59,942 (hdfs-hdfs-sink-2-call-runner-6) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201772.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201772
2015-05-23 00:47:00,026 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201773.tmp
2015-05-23 00:59:59,762 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter$5.call(BucketWriter.java:429)] Closing idle bucketWriter hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803797.tmp at 1432324799761
2015-05-23 00:59:59,765 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803797.tmp
2015-05-23 00:59:59,787 (hdfs-hdfs-sink-2-call-runner-9) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803797.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150522/user_tweets.1432234803797
2015-05-23 00:59:59,791 (hdfs-hdfs-sink-2-roll-timer-0) [INFO - org.apache.flume.sink.hdfs.HDFSEventSink$1.run(HDFSEventSink.java:394)] Writer callback called.
2015-05-23 01:12:27,205 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201773.tmp
2015-05-23 01:12:27,248 (hdfs-hdfs-sink-2-call-runner-7) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201773.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201773
2015-05-23 01:12:27,325 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201774.tmp
2015-05-23 01:32:05,004 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201774.tmp
2015-05-23 01:32:05,057 (hdfs-hdfs-sink-2-call-runner-5) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201774.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201774
2015-05-23 01:32:05,133 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201775.tmp
2015-05-23 01:56:07,062 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201775.tmp
2015-05-23 01:56:07,096 (hdfs-hdfs-sink-2-call-runner-8) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201775.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201775
2015-05-23 01:56:07,147 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201776.tmp
2015-05-23 02:47:39,609 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.close(BucketWriter.java:363)] Closing hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201776.tmp
2015-05-23 02:47:39,654 (hdfs-hdfs-sink-2-call-runner-3) [INFO - org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:629)] Renaming hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201776.tmp to hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201776
2015-05-23 02:47:39,746 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:234)] Creating hdfs://pti-base.insafanalytics.com:8020/user/flume/user-tweets/20150523/user_tweets.1432321201777.tmp
2015-05-23 04:19:04,909 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4002ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:05,024 (lifecycleSupervisor-1-0-EventThread) [INFO - org.I0Itec.zkclient.ZkClient.processStateChanged(ZkClient.java:449)] zookeeper state changed (Disconnected)
2015-05-23 04:19:05,291 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:05,292 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:05,293 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:07,342 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:10,347 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4951ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:10,929 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:10,930 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:10,930 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:12,243 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:15,248 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4217ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:15,757 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:15,758 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:15,758 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:17,357 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:19,969 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:20,362 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4503ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:20,973 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:21,335 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:21,336 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:21,336 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:21,977 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 32 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:22,940 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:22,981 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 33 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:23,988 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 34 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:24,994 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 35 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:25,943 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4506ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:25,998 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 36 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:26,283 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:26,284 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:26,284 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:27,001 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 37 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:28,004 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 38 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:28,022 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:29,007 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 39 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:30,012 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 40 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:30,671 (ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67) [WARN - kafka.utils.Logging$class.warn(Logging.scala:83)] Reconnect due to socket error: null
2015-05-23 04:19:30,701 (ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67) [ERROR - kafka.utils.Logging$class.error(Logging.scala:103)] [ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67], Error in fetch Name: FetchRequest; Version: 0; CorrelationId: 6068714; ClientId: flume-ConsumerFetcherThread-flume_pti-base.insafanalytics.com-1431709326715-a87037b9-0-67; ReplicaId: -1; MaxWait: 100 ms; MinBytes: 1 bytes; RequestInfo: [user-tweets,0] -> PartitionFetchInfo(168482,1048576)
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at kafka.network.BlockingChannel.connect(BlockingChannel.scala:57)
	at kafka.consumer.SimpleConsumer.connect(SimpleConsumer.scala:44)
	at kafka.consumer.SimpleConsumer.reconnect(SimpleConsumer.scala:57)
	at kafka.consumer.SimpleConsumer.liftedTree1$1(SimpleConsumer.scala:79)
	at kafka.consumer.SimpleConsumer.kafka$consumer$SimpleConsumer$$sendRequest(SimpleConsumer.scala:71)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(SimpleConsumer.scala:109)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:109)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1$$anonfun$apply$mcV$sp$1.apply(SimpleConsumer.scala:109)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply$mcV$sp(SimpleConsumer.scala:108)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:108)
	at kafka.consumer.SimpleConsumer$$anonfun$fetch$1.apply(SimpleConsumer.scala:108)
	at kafka.metrics.KafkaTimer.time(KafkaTimer.scala:33)
	at kafka.consumer.SimpleConsumer.fetch(SimpleConsumer.scala:107)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:96)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:88)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:51)
2015-05-23 04:19:30,713 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4328ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:31,017 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 41 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:31,135 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:31,136 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:31,137 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:32,020 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 42 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:32,372 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:33,026 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 43 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:34,028 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 44 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:35,032 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 45 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:35,373 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4135ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:35,491 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:35,492 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:35,492 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:36,037 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 46 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:37,042 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 47 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:37,249 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:38,045 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 48 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:39,047 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 49 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:40,053 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 50 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:40,251 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4659ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:40,939 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:40,940 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:40,940 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:41,058 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 51 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:42,060 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 52 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:42,763 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:43,063 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 53 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:44,071 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 54 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:45,074 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 55 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:45,768 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4728ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:45,955 (ResponseProcessor for block BP-284960723-45.55.231.94-1430004888471:blk_1073814889_74440) [WARN - org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:966)] DFSOutputStream ResponseProcessor exception  for block BP-284960723-45.55.231.94-1430004888471:blk_1073814889_74440
java.net.SocketTimeoutException: 70000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/45.55.231.94:53147 remote=/45.55.231.94:50010]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:879)
2015-05-23 04:19:45,956 (DataStreamer for file /user/flume/user-tweets/20150523/user_tweets.1432321201777.tmp block BP-284960723-45.55.231.94-1430004888471:blk_1073814889_74440) [WARN - org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1223)] Error Recovery for block BP-284960723-45.55.231.94-1430004888471:blk_1073814889_74440 in pipeline DatanodeInfoWithStorage[45.55.231.94:50010,DS-81e4400b-00b5-486d-b77a-ea0687361919,DISK], DatanodeInfoWithStorage[45.55.231.81:50010,DS-50b03bbc-a7d4-4b8b-bc6e-9886eb8c9581,DISK]: bad datanode DatanodeInfoWithStorage[45.55.231.94:50010,DS-81e4400b-00b5-486d-b77a-ea0687361919,DISK]
2015-05-23 04:19:45,972 (DataStreamer for file /user/flume/user-tweets/20150523/user_tweets.1432321201777.tmp block BP-284960723-45.55.231.94-1430004888471:blk_1073814889_74440) [WARN - org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:703)] DataStreamer Exception
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updateBlockForPipeline(ClientNamenodeProtocolTranslatorPB.java:877)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.updateBlockForPipeline(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1278)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1016)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:560)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 14 more
2015-05-23 04:19:46,077 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 56 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:46,260 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:46,261 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:46,261 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:47,081 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 57 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:47,995 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:48,086 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 58 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:49,092 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 59 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:50,095 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 60 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:50,996 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4634ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:51,097 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 61 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:51,373 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:51,374 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:51,374 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:52,099 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 62 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:53,102 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 63 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:53,108 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:54,105 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 64 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:55,109 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 65 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:56,111 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4636ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:19:56,116 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 66 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:57,118 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 67 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:57,171 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:57,172 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:19:57,172 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:19:58,121 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 68 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:19:58,610 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:19:59,125 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 69 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:00,129 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 70 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:01,132 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 71 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:01,613 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4341ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:02,135 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 72 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:02,288 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:02,288 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:02,289 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:03,140 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 73 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:03,923 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:04,142 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 74 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:05,146 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 75 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:06,149 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 76 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:06,928 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4537ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:07,151 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 77 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:07,558 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:07,559 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:07,559 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:08,154 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 78 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:09,158 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 79 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:09,241 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:10,164 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 80 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:11,169 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 81 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:12,172 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 82 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:12,245 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4586ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:12,488 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:12,489 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:12,489 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:13,174 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 83 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:13,615 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:14,182 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 84 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:15,186 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 85 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:16,191 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 86 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:16,618 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4028ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:17,196 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 87 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:17,576 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:17,577 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:17,577 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:18,202 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 88 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:19,033 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:19,207 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 89 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:20,211 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 90 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:21,215 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 91 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:22,036 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4352ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:22,220 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 92 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:22,643 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:22,644 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:22,644 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:23,224 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 93 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:24,015 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:24,228 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 94 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:25,232 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 95 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:26,236 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 96 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:27,019 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4273ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:27,239 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 97 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:27,435 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:27,436 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:27,436 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:28,244 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 98 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:29,253 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 99 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:29,535 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:30,259 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 100 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:31,262 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 101 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:32,266 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 102 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:32,539 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 5002ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:33,096 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:33,098 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:33,098 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:33,269 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 103 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:34,272 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 104 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:34,345 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:35,276 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 105 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:36,279 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 106 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:37,281 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 107 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:37,348 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4149ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:38,053 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:38,054 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:38,055 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:38,284 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 108 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:39,289 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 109 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:40,089 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:40,293 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 110 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:41,298 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 111 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:42,300 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 112 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:43,091 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4936ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:43,302 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 113 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:44,163 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:44,164 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:44,164 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:44,305 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 114 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:45,310 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 115 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:46,169 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:46,315 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 116 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:47,319 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 117 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:48,323 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 118 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:49,173 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4907ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:49,326 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 119 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:50,087 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:50,088 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:50,088 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:50,330 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 120 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:51,334 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 121 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:52,054 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:52,338 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 122 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:53,342 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 123 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:54,345 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 124 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:55,055 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4866ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:20:55,249 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:55,250 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:20:55,250 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:20:55,351 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 125 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:56,356 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 126 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:56,532 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:20:57,360 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 127 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:58,365 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 128 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:59,370 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 129 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:20:59,535 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1096)] Client session timed out, have not heard from server in 4184ms for sessionid 0x14d5867a7190000, closing socket connection and attempting reconnect
2015-05-23 04:21:00,373 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 130 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:21:00,386 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
2015-05-23 04:21:00,386 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [ERROR - org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:278)] Unable to open socket to localhost/0:0:0:0:0:0:0:1:2181
2015-05-23 04:21:00,386 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [WARN - org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1102)] Session 0x14d5867a7190000 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.zookeeper.ClientCnxnSocketNIO.registerAndConnect(ClientCnxnSocketNIO.java:266)
	at org.apache.zookeeper.ClientCnxnSocketNIO.connect(ClientCnxnSocketNIO.java:276)
	at org.apache.zookeeper.ClientCnxn$SendThread.startConnect(ClientCnxn.java:967)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1003)
2015-05-23 04:21:01,376 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 131 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
2015-05-23 04:21:01,633 (lifecycleSupervisor-1-0-SendThread(localhost:2181)) [INFO - org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:975)] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/05/22 19:21:01 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
15/05/22 19:21:01 INFO ExecutorRunner: Killing process!
15/05/22 19:21:01 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150522150021-0029/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
2015-05-23 04:21:01,997 (agent-shutdown-hook) [INFO - org.apache.flume.lifecycle.LifecycleSupervisor.stop(LifecycleSupervisor.java:79)] Stopping lifecycle supervisor 10
2015-05-23 04:21:02,036 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:150)] Component type: CHANNEL, name: hdfs-channel-2 stopped
2015-05-23 04:21:02,037 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:156)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.start.time == 1431709326074
2015-05-23 04:21:02,037 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:162)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.stop.time == 1432336862036
2015-05-23 04:21:02,037 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.capacity == 10000
2015-05-23 04:21:02,037 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.current.size == 0
2015-05-23 04:21:02,038 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.event.put.attempt == 87111
2015-05-23 04:21:02,038 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.event.put.success == 87111
2015-05-23 04:21:02,038 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.event.take.attempt == 206181
2015-05-23 04:21:02,038 (agent-shutdown-hook) [INFO - org.apache.flume.instrumentation.MonitoredCounterGroup.stop(MonitoredCounterGroup.java:178)] Shutdown Metric for type: CHANNEL, name: hdfs-channel-2. channel.event.take.success == 87111
2015-05-23 04:21:02,038 (PollableSourceRunner-KafkaSource-kafka-source-2) [ERROR - org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:153)] KafkaSource EXCEPTION, {}
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2017)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2095)
	at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:65)
	at kafka.consumer.ConsumerIterator.makeNext(ConsumerIterator.scala:33)
	at kafka.utils.IteratorTemplate.maybeComputeNext(IteratorTemplate.scala:66)
	at kafka.utils.IteratorTemplate.hasNext(IteratorTemplate.scala:58)
	at org.apache.flume.source.kafka.KafkaSource.hasNext(KafkaSource.java:248)
	at org.apache.flume.source.kafka.KafkaSource.process(KafkaSource.java:97)
	at org.apache.flume.source.PollableSourceRunner$PollingRunner.run(PollableSourceRunner.java:139)
	at java.lang.Thread.run(Thread.java:745)
2015-05-23 04:21:02,383 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 132 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
15/05/22 19:21:02 INFO Worker: Executor app-20150522150021-0029/1 finished with state EXITED message Command exited with code 143 exitStatus 143
2015-05-23 04:21:03,392 (LeaseRenewer:root@pti-base.insafanalytics.com:8020) [WARN - org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:458)] Failed to renew lease for [DFSClient_NONMAPREDUCE_1591115404_33] for 133 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "pti-base.insafanalytics.com/45.55.231.94"; destination host is: "pti-base.insafanalytics.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy12.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:876)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 16 more
