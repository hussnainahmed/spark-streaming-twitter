SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/avro-tools-1.7.6-cdh5.4.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/05/13 08:56:23 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
15/05/13 08:56:26 INFO SecurityManager: Changing view acls to: root
15/05/13 08:56:26 INFO SecurityManager: Changing modify acls to: root
15/05/13 08:56:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/05/13 08:56:27 INFO Slf4jLogger: Slf4jLogger started
15/05/13 08:56:27 INFO Remoting: Starting remoting
15/05/13 08:56:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943]
15/05/13 08:56:28 INFO Utils: Successfully started service 'sparkWorker' on port 44943.
15/05/13 08:56:28 INFO Worker: Starting Spark worker pti-base.insafanalytics.com:44943 with 2 cores, 3.0 GB RAM
15/05/13 08:56:28 INFO Worker: Running Spark version 1.3.0
15/05/13 08:56:28 INFO Worker: Spark home: /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark
15/05/13 08:56:28 INFO Server: jetty-8.y.z-SNAPSHOT
15/05/13 08:56:28 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8081
15/05/13 08:56:28 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
15/05/13 08:56:28 INFO WorkerWebUI: Started WorkerWebUI at http://pti-base.insafanalytics.com:8081
15/05/13 08:56:28 INFO Worker: Connecting to master akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079/user/Master...
15/05/13 08:56:29 INFO Worker: Successfully registered with master spark://pti-base.insafanalytics.com:7079
15/05/13 09:06:11 INFO Worker: Asked to launch executor app-20150513090611-0000/0 for PTITwitterStream
15/05/13 09:06:11 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=38673" "-Xms512M" "-Xmx512M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:38673/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "pti-base.insafanalytics.com" "--cores" "2" "--app-id" "app-20150513090611-0000" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943/user/Worker"
15/05/13 09:32:38 ERROR LogPage: Error getting stdout logs from directory /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150513090611-0000/2/
java.lang.NullPointerException
	at scala.collection.mutable.ArrayOps$ofRef$.newBuilder$extension(ArrayOps.scala:112)
	at scala.collection.mutable.ArrayOps$ofRef.newBuilder(ArrayOps.scala:108)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:262)
	at scala.collection.mutable.ArrayOps$ofRef.filter(ArrayOps.scala:108)
	at org.apache.spark.util.logging.RollingFileAppender$.getSortedRolledOverFiles(RollingFileAppender.scala:153)
	at org.apache.spark.deploy.worker.ui.LogPage.getLog(LogPage.scala:133)
	at org.apache.spark.deploy.worker.ui.LogPage.render(LogPage.scala:75)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:69)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.spark-project.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.spark-project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:501)
	at org.spark-project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.spark-project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.spark-project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.spark-project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)
	at org.spark-project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.spark-project.jetty.server.Server.handle(Server.java:370)
	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)
	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)
	at org.spark-project.jetty.http.HttpParser.parseNext(HttpParser.java:644)
	at org.spark-project.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)
	at org.spark-project.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)
15/05/13 09:32:40 ERROR LogPage: Error getting stdou logs from directory /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150513090611-0000/2/
java.lang.NullPointerException
	at scala.collection.mutable.ArrayOps$ofRef$.newBuilder$extension(ArrayOps.scala:112)
	at scala.collection.mutable.ArrayOps$ofRef.newBuilder(ArrayOps.scala:108)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:262)
	at scala.collection.mutable.ArrayOps$ofRef.filter(ArrayOps.scala:108)
	at org.apache.spark.util.logging.RollingFileAppender$.getSortedRolledOverFiles(RollingFileAppender.scala:153)
	at org.apache.spark.deploy.worker.ui.LogPage.getLog(LogPage.scala:133)
	at org.apache.spark.deploy.worker.ui.LogPage.render(LogPage.scala:75)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:69)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.spark-project.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.spark-project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:501)
	at org.spark-project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.spark-project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.spark-project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.spark-project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)
	at org.spark-project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.spark-project.jetty.server.Server.handle(Server.java:370)
	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)
	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)
	at org.spark-project.jetty.http.HttpParser.parseNext(HttpParser.java:644)
	at org.spark-project.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)
	at org.spark-project.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)
15/05/13 12:04:19 INFO Worker: Executor app-20150513090611-0000/0 finished with state EXITED message Command exited with code 1 exitStatus 1
15/05/13 12:04:19 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A51857-2#-1341302477] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 12:04:19 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57799
]
15/05/13 12:04:19 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57799
]
15/05/13 12:04:19 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:57799]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:57799
]
15/05/13 12:04:20 INFO Worker: Asked to kill unknown executor app-20150513090611-0000/0
15/05/13 12:04:20 INFO Worker: Cleaning up local directories for application app-20150513090611-0000
15/05/13 12:28:36 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40pti-base.insafanalytics.com%3A7079-1#1513732509] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 12:28:36 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:36 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:36 INFO Worker: Connecting to master akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079/user/Master...
15/05/13 12:28:36 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:36 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:36 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:36 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:36 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:36 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:36 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:36 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:36 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:36 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:36 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:36 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:36 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:36 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:36 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:36 INFO RemoteActorRefProvider$RemoteDeadLetterActorRef: Message [org.apache.spark.deploy.DeployMessages$RegisterWorker] from Actor[akka://sparkWorker/user/Worker#1778173201] to Actor[akka://sparkWorker/deadLetters] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 12:28:50 INFO Worker: Retrying connection to master (attempt # 1)
15/05/13 12:28:50 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:50 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:50 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:50 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:50 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:50 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:50 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:50 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:50 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:50 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:28:50 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:28:50 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:28:50 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:28:50 INFO RemoteActorRefProvider$RemoteDeadLetterActorRef: Message [org.apache.spark.deploy.DeployMessages$RegisterWorker] from Actor[akka://sparkWorker/user/Worker#1778173201] to Actor[akka://sparkWorker/deadLetters] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 12:29:04 INFO Worker: Retrying connection to master (attempt # 2)
15/05/13 12:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:29:04 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:29:04 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:29:04 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:29:04 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:29:04 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:29:04 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:29:04 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:29:04 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:29:04 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:29:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]: Error [Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:7079
]
15/05/13 12:29:04 INFO Worker: Disassociated [akka.tcp://sparkWorker@pti-base.insafanalytics.com:44943] -> [akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079] Disassociated !
15/05/13 12:29:04 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
15/05/13 12:29:04 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
15/05/13 12:29:04 INFO RemoteActorRefProvider$RemoteDeadLetterActorRef: Message [org.apache.spark.deploy.DeployMessages$RegisterWorker] from Actor[akka://sparkWorker/user/Worker#1778173201] to Actor[akka://sparkWorker/deadLetters] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 12:29:18 INFO Worker: Retrying connection to master (attempt # 3)
15/05/13 12:29:19 INFO Worker: Successfully registered with master spark://pti-base.insafanalytics.com:7079
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/avro-tools-1.7.6-cdh5.4.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/05/13 12:35:39 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
15/05/13 12:35:42 INFO SecurityManager: Changing view acls to: root
15/05/13 12:35:42 INFO SecurityManager: Changing modify acls to: root
15/05/13 12:35:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/05/13 12:35:43 INFO Slf4jLogger: Slf4jLogger started
15/05/13 12:35:43 INFO Remoting: Starting remoting
15/05/13 12:35:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@pti-base.insafanalytics.com:42895]
15/05/13 12:35:44 INFO Utils: Successfully started service 'sparkWorker' on port 42895.
15/05/13 12:35:44 INFO Worker: Starting Spark worker pti-base.insafanalytics.com:42895 with 2 cores, 1024.0 MB RAM
15/05/13 12:35:44 INFO Worker: Running Spark version 1.3.0
15/05/13 12:35:44 INFO Worker: Spark home: /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark
15/05/13 12:35:44 INFO Server: jetty-8.y.z-SNAPSHOT
15/05/13 12:35:45 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8081
15/05/13 12:35:45 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
15/05/13 12:35:45 INFO WorkerWebUI: Started WorkerWebUI at http://pti-base.insafanalytics.com:8081
15/05/13 12:35:45 INFO Worker: Connecting to master akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079/user/Master...
15/05/13 12:35:45 INFO Worker: Successfully registered with master spark://pti-base.insafanalytics.com:7079
15/05/13 12:38:15 INFO Worker: Asked to launch executor app-20150513123814-0000/0 for PTITwitterStream
15/05/13 12:38:15 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=53626" "-Xms512M" "-Xmx512M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:53626/user/CoarseGrainedScheduler" "--executor-id" "0" "--hostname" "pti-base.insafanalytics.com" "--cores" "2" "--app-id" "app-20150513123814-0000" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:42895/user/Worker"
15/05/13 14:51:22 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
15/05/13 14:51:22 INFO ExecutorRunner: Killing process!
15/05/13 14:51:22 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150513123814-0000/0/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/jars/avro-tools-1.7.6-cdh5.4.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
15/05/13 15:09:55 INFO Worker: Registered signal handlers for [TERM, HUP, INT]
15/05/13 15:09:57 INFO SecurityManager: Changing view acls to: root
15/05/13 15:09:57 INFO SecurityManager: Changing modify acls to: root
15/05/13 15:09:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/05/13 15:09:59 INFO Slf4jLogger: Slf4jLogger started
15/05/13 15:09:59 INFO Remoting: Starting remoting
15/05/13 15:09:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665]
15/05/13 15:09:59 INFO Utils: Successfully started service 'sparkWorker' on port 49665.
15/05/13 15:10:00 INFO Worker: Starting Spark worker pti-base.insafanalytics.com:49665 with 2 cores, 1024.0 MB RAM
15/05/13 15:10:00 INFO Worker: Running Spark version 1.3.0
15/05/13 15:10:00 INFO Worker: Spark home: /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark
15/05/13 15:10:00 INFO Server: jetty-8.y.z-SNAPSHOT
15/05/13 15:10:00 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:8081
15/05/13 15:10:00 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
15/05/13 15:10:00 INFO WorkerWebUI: Started WorkerWebUI at http://pti-base.insafanalytics.com:8081
15/05/13 15:10:00 INFO Worker: Connecting to master akka.tcp://sparkMaster@pti-base.insafanalytics.com:7079/user/Master...
15/05/13 15:10:01 INFO Worker: Successfully registered with master spark://pti-base.insafanalytics.com:7079
15/05/13 15:12:32 INFO Worker: Asked to launch executor app-20150513151232-0000/1 for PTITwitterStream
15/05/13 15:12:32 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=39429" "-Xms512M" "-Xmx512M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:39429/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "2" "--app-id" "app-20150513151232-0000" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665/user/Worker"
15/05/13 22:34:04 INFO Worker: Executor app-20150513151232-0000/1 finished with state EXITED message Command exited with code 1 exitStatus 1
15/05/13 22:34:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A38580-2#1145293798] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/13 22:34:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59158
]
15/05/13 22:34:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59158
]
15/05/13 22:34:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:59158]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:59158
]
15/05/13 22:34:04 INFO Worker: Asked to kill unknown executor app-20150513151232-0000/1
15/05/13 22:34:04 INFO Worker: Cleaning up local directories for application app-20150513151232-0000
15/05/14 04:03:59 INFO Worker: Asked to launch executor app-20150514040359-0001/1 for PTITwitterStream
15/05/14 04:03:59 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=52774" "-Xms512M" "-Xmx512M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:52774/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "2" "--app-id" "app-20150514040359-0001" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665/user/Worker"
15/05/14 04:07:22 ERROR LogPage: Error getting stderr logs from directory /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150513151232-0000/2/
java.lang.NullPointerException
	at scala.collection.mutable.ArrayOps$ofRef$.newBuilder$extension(ArrayOps.scala:112)
	at scala.collection.mutable.ArrayOps$ofRef.newBuilder(ArrayOps.scala:108)
	at scala.collection.TraversableLike$class.filter(TraversableLike.scala:262)
	at scala.collection.mutable.ArrayOps$ofRef.filter(ArrayOps.scala:108)
	at org.apache.spark.util.logging.RollingFileAppender$.getSortedRolledOverFiles(RollingFileAppender.scala:153)
	at org.apache.spark.deploy.worker.ui.LogPage.getLog(LogPage.scala:133)
	at org.apache.spark.deploy.worker.ui.LogPage.render(LogPage.scala:75)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.WebUI$$anonfun$attachPage$1.apply(WebUI.scala:68)
	at org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:69)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:735)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)
	at org.spark-project.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)
	at org.spark-project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:501)
	at org.spark-project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)
	at org.spark-project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)
	at org.spark-project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)
	at org.spark-project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)
	at org.spark-project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:255)
	at org.spark-project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)
	at org.spark-project.jetty.server.Server.handle(Server.java:370)
	at org.spark-project.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)
	at org.spark-project.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)
	at org.spark-project.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)
	at org.spark-project.jetty.http.HttpParser.parseNext(HttpParser.java:644)
	at org.spark-project.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)
	at org.spark-project.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)
	at org.spark-project.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)
	at org.spark-project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)
	at org.spark-project.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)
	at java.lang.Thread.run(Thread.java:745)
15/05/14 11:56:04 INFO Worker: Asked to kill executor app-20150514040359-0001/1
15/05/14 11:56:04 INFO ExecutorRunner: Runner thread for executor app-20150514040359-0001/1 interrupted
15/05/14 11:56:04 INFO ExecutorRunner: Killing process!
15/05/14 11:56:04 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150514040359-0001/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/14 11:56:04 INFO Worker: Executor app-20150514040359-0001/1 finished with state KILLED exitStatus 1
15/05/14 11:56:04 INFO Worker: Cleaning up local directories for application app-20150514040359-0001
15/05/14 11:56:04 INFO LocalActorRef: Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%4045.55.231.94%3A35562-6#-1790570646] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
15/05/14 11:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53692
]
15/05/14 11:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53692
]
15/05/14 11:56:04 ERROR EndpointWriter: AssociationError [akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665] -> [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]: Error [Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@pti-base.insafanalytics.com:53692]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: pti-base.insafanalytics.com/45.55.231.94:53692
]
15/05/14 13:32:15 INFO Worker: Asked to launch executor app-20150514133215-0002/1 for PTITwitterStream
15/05/14 13:32:15 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/jre-1.7.0-openjdk.x86_64/bin/java" "-cp" "/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:/var/lib/hive/datafu-1.2.0.jar:/var/lib/hive/spark-csv_2.10-1.0.0.jar:/var/lib/hive/ddf_spark_2.10-1.1.jar:/var/lib/hive/spark-hbase-connector-0.9.5.jar:/var/lib/hive/nexr-hive-udf-0.2-SNAPSHOT.jar:/var/lib/hive/hive-serdes-1.0-SNAPSHOT.jar:/var/lib/hive/csv-serde-1.1.2-0.11.0-all.jar:/var/lib/hive/joda-time-2.4.jar:/var/lib/hive/nscala-time_2.10-0.2.0.jar:/var/lib/hive/esper-5.2.0.jar:/var/lib/hive/spark-streaming-kafka-assembly-1.3.0-SNAPSHOT.jar:::/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/conf:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/lib/spark-assembly-1.3.0-cdh5.4.0-hadoop2.6.0-cdh5.4.0.jar:/etc/hadoop/conf:/opt/cloudera/parcels/CDH/lib/hadoop/client/*:/etc/hadoop/conf/:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/libexec/../../hadoop-yarn/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*:/opt/cloudera/parcels/CDH/lib/hive/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/flume-ng/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../parquet/lib/*:/opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/hadoop/../avro/*" "-XX:MaxPermSize=128m" "-Dspark.driver.port=52700" "-Xms512M" "-Xmx512M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "akka.tcp://sparkDriver@pti-base.insafanalytics.com:52700/user/CoarseGrainedScheduler" "--executor-id" "1" "--hostname" "pti-base.insafanalytics.com" "--cores" "2" "--app-id" "app-20150514133215-0002" "--worker-url" "akka.tcp://sparkWorker@pti-base.insafanalytics.com:49665/user/Worker"
15/05/14 16:08:17 ERROR Worker: RECEIVED SIGNAL 15: SIGTERM
15/05/14 16:08:17 INFO ExecutorRunner: Killing process!
15/05/14 16:08:17 INFO ExecutorRunner: Killing process!
15/05/14 16:08:17 INFO Worker: Unknown Executor app-20150513151232-0000/1 finished with state EXITED message Worker shutting down exitStatus 1
15/05/14 16:08:17 ERROR FileAppender: Error writing stream to file /opt/cloudera/parcels/CDH-5.4.0-1.cdh5.4.0.p0.27/lib/spark/work/app-20150514133215-0002/1/stderr
java.io.IOException: Stream closed
	at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:162)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:272)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at java.io.FilterInputStream.read(FilterInputStream.java:107)
	at org.apache.spark.util.logging.FileAppender.appendStreamToFile(FileAppender.scala:70)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply$mcV$sp(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.logging.FileAppender$$anon$1$$anonfun$run$1.apply(FileAppender.scala:39)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1617)
	at org.apache.spark.util.logging.FileAppender$$anon$1.run(FileAppender.scala:38)
15/05/14 16:08:18 INFO Worker: Executor app-20150514133215-0002/1 finished with state EXITED message Command exited with code 143 exitStatus 143
